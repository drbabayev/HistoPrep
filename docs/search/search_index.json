{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to HistoPrep's documentation Histological slide images require intensive preprocessing before they can be fed for macine learning models. With HistoPrep , its easy to preprocess histological slide images! You can either use HistoPrep as a python module... import histoprep # Read slide. reader = histoprep.SlideReader(\"/path/to/slide.svs\") # Save tiles. tile_metadata = reader.save_tiles( output_dir=\"/processed_slides/\", coordinates=reader.get_tile_coordinates( width=512, overlap=0.1, max_background=0.6, ), ) # Detect outliers automatically! detector = histoprep.OutlierDetector(tile_metadata, num_clusters=20) # Will plot clusters as \"most_likely_outlier\" -> \"least_likely_outlier\". detector.plot_clusters() # Outliers can be marked based on the visual inspection. clean_data = tile_metadata.iloc[detector.clusters > 3, :] ... or as an excecutable from your command line to cut more slides easily! jopo666@MacBook$ HistoPrep [input_dir] [output_dir] [width] {optional arguments}","title":"Home"},{"location":"#welcome-to-histopreps-documentation","text":"Histological slide images require intensive preprocessing before they can be fed for macine learning models. With HistoPrep , its easy to preprocess histological slide images! You can either use HistoPrep as a python module... import histoprep # Read slide. reader = histoprep.SlideReader(\"/path/to/slide.svs\") # Save tiles. tile_metadata = reader.save_tiles( output_dir=\"/processed_slides/\", coordinates=reader.get_tile_coordinates( width=512, overlap=0.1, max_background=0.6, ), ) # Detect outliers automatically! detector = histoprep.OutlierDetector(tile_metadata, num_clusters=20) # Will plot clusters as \"most_likely_outlier\" -> \"least_likely_outlier\". detector.plot_clusters() # Outliers can be marked based on the visual inspection. clean_data = tile_metadata.iloc[detector.clusters > 3, :] ... or as an excecutable from your command line to cut more slides easily! jopo666@MacBook$ HistoPrep [input_dir] [output_dir] [width] {optional arguments}","title":"Welcome to HistoPrep's documentation"},{"location":"api/","text":"package histoprep class SlideReader ( path , verbose=False , preferred_dimension=4096 , threshold=None , threshold_multiplier=1.05 , max_dimension=16384 ) Reader for large slide images with extended functionality such as tissue detection, tile coordinate extraction, dearraying TMA spots and saving tiles. Parameters path (str) \u2014 Path to slide image. verbose (bool, optional) \u2014 Set to True to get verbose output. Defaults to False. preferred_dimension (int, optional) \u2014 Preferred maximum dimension for the for the generated thumbnail. Defaults to 4096. threshold (int, optional) \u2014 Treshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. threshold_multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with threshold_multiplier . Used only if threshold is None. Defaults to 1.05. max_dimension (int, optional) \u2014 Maximum dimension for the generated thumbnail. Smaller thumbnails are preferred, but in the absence of these, the first level with all dimensions less than max_dimension is chosen. Defaults to 16_384. Attributes annotated_thumbnail_spots (Image) \u2014 Thumbnail image annotated with the spot coordinates. annotated_thumbnail_tiles (Image) \u2014 Thumbnail image annotated with the tile coordinates. dimensions (int, int) \u2014 Slide image dimensions. level_dimensions (dict(int: (int, int))) \u2014 Downsamples for each level. level_downsamples (dict(int: (float, float))) \u2014 Dimensions for each level. spot_mask (Image) \u2014 TMA spot mask (0=background, 1=spot). spot_metadata (Image) \u2014 Metadata for TMA spots. thumbnail (Image) \u2014 Thumbnail image of the slide. thumbnail_downsample (Image) \u2014 Downsample for the thumbnail image. tile_metadata (Image) \u2014 Metadata for saved tiles. tissue_mask (Image) \u2014 Tissue mask (0=background, 1=tissue). tissue_threshold (int) \u2014 Threshold for tissue detection. Raises FileNotFoundError \u2014 File not found. IOError \u2014 File not readable by HistoPrep. NotADirectoryError \u2014 Scratch directory exists, but isn't a directory. Usage: from histoprep import SlideReader # Load tile images. reader = SlideReader(\"/path/to/slide.tiff\") thumbnail = reader.get_thumbnail() thresh, tissue_mask = reader.detect_tissue() coords = reader.get_tile_coordinates( width=512, overlap=0.1, tissue_mask=tissue_mask ) tiles = [reader.read_region(xywh) for xywh in coords] Methods dearray ( kernel_size , iterations , min_area , max_area ) (DataFrame) \u2014 Dearray TMA spots. detect_tissue ( threshold , multiplier , sigma , remove_white ) \u2014 Detect tissue from slide image. get_thumbnail ( preferred_dimension , level , return_arr , fill , return_level ) (ndarray or Image) \u2014 Get thumbnail image of the slide. get_tile_coordinates ( width , overlap , height , level , tissue_mask , max_background ) (list of (int, int, int, int)) \u2014 Get tile coordinates for the slide. read_region ( xywh , level , return_arr , fill ) (Image or ndarray) \u2014 Read region from slide. save_spots ( output_dir , overwrite , image_format , quality , num_workers , num_retries , display_progress ) (DataFrame) \u2014 Save TMA spot images from a slide. save_tiles ( output_dir , coordinates , level , preprocess_metrics , overwrite , image_format , quality , num_workers , num_retries , display_progress ) \u2014 Save tile images from a slide. method read_region ( xywh , level=0 , return_arr=False , fill=255 ) Read region from slide. Parameters xywh (int, int, int, int) \u2014 Region defined by X, Y, width and height. return_arr (bool, optional) \u2014 Return region as an uint8 array instead of a Pil image. Defaults to False. fill (int, optional) \u2014 Fill overbound areas with this value. If None, raises an error when the region goes out of bounds. Defaults to 255. Raises ValueError \u2014 XYWH, level or fill are not integers. ValueError \u2014 Negative coordinates. ValueError \u2014 Width or height less than 1. ValueError \u2014 Region overbound without a fill value. Returns (Image or ndarray) Image of the region. Example from histoprep import SlideReader slide = SlideReader(\"/path/to/slide.tiff\") tile_image = slide.read_region(x=0, y=0, w=1024, h=1024) method get_thumbnail ( preferred_dimension=4096 , level=None , return_arr=False , fill=255 , return_level=False ) Get thumbnail image of the slide. Running this method updates the thumbnail attribute. Parameters preferred_dimension (int, optional) \u2014 Selects the first level which has both dimensions smaller than preferred_dimension . If not found, selects the smallest thumbnail with all dimensions less than MAX_DIMENSION attribute. Defaults to 4096. level (int, optional) \u2014 Overwrites max_dimension and loads a specific level. Defaults to None. return_arr (bool, optional) \u2014 Return an uint8 array instead of PIL Image. Defaults to False. fill (int, optional) \u2014 Fill out of bounds regions. Defaults to 255. return_level (bool, optional) \u2014 Return the thumbnail level. Defaults to False. Raises ValueError \u2014 No levels with dimensions less than MAX_DIMENSION . ValueError \u2014 Level does not exist. Returns (ndarray or Image) Thumbnail image. Example from histoprep import SlideReader reader = Slidereader(\"/path/to/slide.tiff\") thumbnail = reader.get_thumbnail() method detect_tissue ( threshold=None , multiplier=1.05 , sigma=1.0 , remove_white=True ) Detect tissue from slide image. Running this method updates the tissue_mask attribute. Parameters threshold (int, optional) \u2014 Treshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with multiplier . Used only if threshold is None. Defaults to 1.0. sigma (float, optional) \u2014 Sigma for gaussian blurring. Defaults to 1.05. remove_white (bool, optional) \u2014 Changes completely white regions to the second highest pixel value, before detecting background. This way Otsu's method isn't affected by possibly extreme white areas. Defaults to True. Returns Binary mask with 0=background and 1=tissue. Example from histoprep import SlideReader reader = SlideReader(\"path/to/slide\") thresh, tissue_mask = reader.detect_tissue() method get_tile_coordinates ( width , overlap=0.0 , height=None , level=0 , tissue_mask=None , max_background=0.95 ) Get tile coordinates for the slide. Divides the slide into tiles based on width, height and overlap. These tiles are then filtered based on the amount of background. Running this method updates the annotated_thumbnail_tiles attribute. Parameters width (int) \u2014 Tile width. overlap (float, optional) \u2014 Overlap between neighbouring tiles. Defaults to 0.0. height (int, optional) \u2014 Height of a tile. If None, will be set to width. Defaults to None. level (int, optional) \u2014 Slide level for calculating tile coordinates. Defaults to 0. tissue_mask (ndarray, optional) \u2014 Tissue mask. If None, uses a cached tissue mask. Defaults to None. max_background (float, optional) \u2014 Maximum amount of background in tile. Defaults to 0.95. Returns (list of (int, int, int, int)) XYWH coordinates for each tile. method dearray ( kernel_size=5 , iterations=3 , min_area=0.25 , max_area=3.0 ) Dearray TMA spots. Running this method updates the annotated_thumbnail_spots and spot_mask attributes. Parameters kernel_size (int, optional) \u2014 Kernel size for dilate. Defaults to 5. iterations (int, optional) \u2014 Dilate iterations. Defaults to 3. min_area (float, optional) \u2014 Minimum area for a spot. Defaults to 0.1 and calculated with: median(areas) * min_area max_area (float, optional) \u2014 Maximum area for a spot. Similar to min_area. Defaults to 3.0. Returns (DataFrame) Spot metadata. method save_spots ( output_dir , overwrite=False , image_format='jpeg' , quality=95 , num_workers=20 , num_retries=10 , display_progress=True ) Save TMA spot images from a slide. Parameters output_dir (str) \u2014 Output directory for the processed images. overwrite (bool, optional) \u2014 Overwrite any existing images. Defaults to False. image_format (str, optional) \u2014 Image format. Defaults to \"jpeg\". quality (int, optional) \u2014 Quality of JPEG compression. Defaults to 95. num_workers (int, optional) \u2014 Number of image saving workers. Defaults to the number of CPU cores. num_retries (int, optional) \u2014 Number retries loading any regions, which couldn't be saved the first time. Defaults to 10. display_progress (bool, optional) \u2014 Display progress bar. Defaults to True. Returns (DataFrame) Dataframe with spot bounding boxes. method save_tiles ( output_dir , coordinates , level=0 , preprocess_metrics=PreprocessMetrics(channel_resize=64, quantiles=[0.05, 0.1, 0.5, 0.9, 0.95], sharpness_reduce=max, custom_callback=None) , overwrite=False , image_format='jpeg' , quality=95 , num_workers=20 , num_retries=10 , display_progress=True ) Save tile images from a slide. Parameters output_dir (str) \u2014 Output directory for the processed images. coordinates (list of (int, int, int, int)) \u2014 A list of XYWH coordinates for the tile regions. Can be easily created with the SlideReader.get_tile_coordinates() method. Please note that the level used to create coordinates should, match the level argument for this function. level (int, optional) \u2014 Slide level to read tile images from. This should match the level used to create the coordinates! Defaults to 0. preprocess_metrics (optional) \u2014 Any Callable which takes an image as an input and returns a dictionary. It is recommended to use the histoprep.PreprocessMetrics class, which can be modified with custom functions. Defaults to histoprep.PreprocessMetrics() . overwrite (bool, optional) \u2014 Overwrite any existing images. Defaults to False. image_format (str, optional) \u2014 Image format. Defaults to \"jpeg\". quality (int, optional) \u2014 Quality of JPEG compression. Defaults to 95. num_workers (int, optional) \u2014 Number of image saving workers. Defaults to the number of CPU cores. num_retries (int, optional) \u2014 Number retries loading any regions, which couldn't be saved the first time. Defaults to 10. display_progress (bool, optional) \u2014 Display progress bar. Defaults to True. Returns Tile metadata and preprocessing metrics. class OutlierDetector ( metadata , num_clusters=20 , batch_size=16384 , **kwargs ) Automatic outlier detection from color channel quantile metrics. Kmeans++ is used to cluster each tile into the desired number of clusters. Clusters are ordered by the distance to the origo in decreasing order, and thus the most likely outlier group is first and last groups contain normal images. Parameters metadata (DataFrame) \u2014 Metadata containing columns: [channel_name]_q={quantile} num_clusters (int, optional) \u2014 Number of clusters. Defaults to 20. batch_size (int, optional) \u2014 Batch size for kmeans++. Defaults to 2**14. Attributes cluster_counts (ndarray) \u2014 Number of members in each cluster. cluster_distances (ndarray) \u2014 Cluster mean euclidean distance to the origo. clusters (ndarray) \u2014 Cluster assignments. metrics (ndarray) \u2014 Quantile metrics normalised with: (X - X.mean(0)) / X.std(0) Example import histoprep detector = histoprep.OutlierDetector(metadata, num_clusters=20) detect.plot_clusters(min_distance=10) # From the plots we might see that clusters 0-3 contain outliers. metadata[\"outlier\"] = False metadata.loc[detector.clusters < 4, \"outlier\"] = True Methods pca_representation ( num_components , max_samples , **kwargs ) (ndarray, ndarray) \u2014 Run princical component analysis (PCA) to get a representation of metrics. Does not produce as nice results as UMAP, but it's faster and supported out-of-the-box. plot_cluster ( cluster , num_examples , ncols , px , figsize ) \u2014 Plot example images from a single cluster. plot_clusters ( min_distance , num_examples , ncols , px , figsize ) \u2014 Plot example images from clusters. plot_representation ( coordinates , indices , label_clusters , size , cmap , figsize ) \u2014 Plot representation of metrics. umap_representation ( num_components , num_neighbors , metric , max_samples , verbose , **kwargs ) (ndarray, ndarray) \u2014 Run Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction. method plot_clusters ( min_distance=None , num_examples=256 , ncols=32 , px=64 , figsize=(9.600000000000001, 4.8) ) Plot example images from clusters. Parameters min_distance (int, optional) \u2014 Minimum distance to filter which groups to plot. Defaults to None. num_examples (int, optional) \u2014 Number of example images from each group. Defaults to 256. ncols (int, optional) \u2014 Number of columns for plotting example images. Defaults to 32. px (int, optional) \u2014 Size of each example image. Defaults to 64. figsize (float, float), optional \u2014 Figure size for plotting. Defaults to (default_width * 1.5, default_height) method plot_cluster ( cluster=0 , num_examples=256 , ncols=32 , px=64 , figsize=(9.600000000000001, 4.8) ) Plot example images from a single cluster. Parameters cluster (int, optional) \u2014 Cluster number. Defaults to 0. num_examples (int, optional) \u2014 Number of example images from each group. Defaults to 256. ncols (int, optional) \u2014 Number of columns for plotting example images. Defaults to 32. px (int, optional) \u2014 Size of each example image. Defaults to 64. figsize (float, float), optional \u2014 Figure size for plotting. Defaults to (default_width * 1.5, default_height) method umap_representation ( num_components=2 , num_neighbors=15 , metric='euclidean' , max_samples=100000 , verbose=True , **kwargs ) Run Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction. Parameters num_components (int, optional) \u2014 Number of components, two offers easy visualisation. Defaults to 2. num_neighbors (int, optional) \u2014 Number of neighbours, should be between 2-100. Defaults to 15. max_samples (int, optional) \u2014 UMAP does not handle very large sample sizes well. Increase if you want to go and get coffee. Defaults to 100_000. **kwargs \u2014 Any keyword arguments for umap.UMAP . Returns (ndarray, ndarray) UMAP representation and indices of the selected samples method pca_representation ( num_components=2 , max_samples=1000000 , **kwargs ) Run princical component analysis (PCA) to get a representation of metrics. Does not produce as nice results as UMAP, but it's faster and supported out-of-the-box. Parameters num_components (int, optional) \u2014 Number of components, two offers easy visualisation. Defaults to 2. max_samples (int, optional) \u2014 PCA does handle very large sample sizes well, but this argument can be used to limit the number of samples. Defaults to 1_000_000. **kwargs \u2014 Any keyword arguments for sklearn.decomposition.PCA . Returns (ndarray, ndarray) PCA representation and indices of the selected samples method plot_representation ( coordinates , indices , label_clusters=False , size=0.5 , cmap=None , figsize=(9.600000000000001, 7.199999999999999) ) Plot representation of metrics. Parameters coordinates (ndarray) \u2014 Representation coordinates. indices (ndarray) \u2014 Sample indices returned by {umap, pca}_representation . size (float, optional) \u2014 Size of each dot. Defaults to 0.5. cmap (str, optional) \u2014 Colour map. Defaults to \"plasma\" for distance and \"coolwarm_r\" for clusters. figsize (float, float), optional \u2014 Figure size. Defaults to Defaults to (default_width * 1.5, default_height * 1.5). label_clusers \u2014 Label each cluster in the plot instead of log(distance). class OutlierVisualizer ( metadata ) Visualise preprocessing metrics to identify outliers. Plotting might take a while if metadata contains several million samples. Parameters metadata (DataFrame) \u2014 Metadata with preprocessing metrics. Example import histoprep # Initialize class. visualise = histoprep.OutlierVisualizer(metadata) # Lets visualise tiles with data loss... visualise.plot_histogram_with_examples(column=\"black_pixels\") # ... or with too much background ... visualise.plot_histogram_with_examples(column=\"background\") # ... or if the colour channel variances picked up any outlies. visualise.plot_rgb_std(log_scale=True) visualise.plot_hsv_std(log_scale=True) Methods plot_histogram_with_examples ( column , bins , num_examples , log_scale , figsize ) \u2014 Plot a histogram of column values, with example tiles from each bin. plot_hsv_mean ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of HSV channels for each tile. plot_hsv_quantiles ( bins , log_scale , figsize ) \u2014 Plot the quantile values of RGB channels for each tile. plot_hsv_std ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of HSV channels for each tile. plot_rgb_mean ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of RGB (and gray) channels for each tile. plot_rgb_quantiles ( bins , log_scale , figsize ) \u2014 Plot the quantile values of RGB channels for each tile. plot_rgb_std ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of RGB (and gray) channels for each tile. method plot_rgb_mean ( bins=50 , log_scale=False , figsize=(12.8, 4.8) ) Plot the standard deviation of RGB (and gray) channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h). method plot_rgb_std ( bins=50 , log_scale=False , figsize=(12.8, 4.8) ) Plot the standard deviation of RGB (and gray) channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h). method plot_hsv_mean ( bins=50 , log_scale=False , figsize=(9.600000000000001, 4.8) ) Plot the standard deviation of HSV channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 1.5, default_h). method plot_hsv_std ( bins=50 , log_scale=False , figsize=(9.600000000000001, 4.8) ) Plot the standard deviation of HSV channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 1.5, default_h). method plot_rgb_quantiles ( bins=50 , log_scale=False , figsize=(12.8, 9.6) ) Plot the quantile values of RGB channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). method plot_hsv_quantiles ( bins=50 , log_scale=False , figsize=(12.8, 9.6) ) Plot the quantile values of RGB channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). method plot_histogram_with_examples ( column , bins=30 , num_examples=14 , log_scale=True , figsize=(12.8, 9.6) ) Plot a histogram of column values, with example tiles from each bin. Parameters column (str) \u2014 Name of the column to plot. bins (int, optional) \u2014 Number of bins. Defaults to 30. num_examples (int, optional) \u2014 Number of example images per bin. Defaults to 16. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to True. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). package functional class PreprocessMetrics ( channel_resize=64 , quantiles=[0.05, 0.1, 0.5, 0.9, 0.95] , sharpness_reduce='max' , custom_callback=None ) Class to calculate basic preprocessing metrics for a histological image. Parameters channel_resize (int, optional) \u2014 Image size for F.channel_quantiles() . Defaults to 128. quantiles (list of int, optional) \u2014 RGB and HSV quantiles. Defaults to [0.05, 0.1, 0.5, 0.9, 0.95]. sharpness_reduce (str or list, optional) \u2014 Sharpness reduction method. Defaults to \"max\". custom_callback (optional) \u2014 Custom callback for to calculate new metrics. Defaults to None. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") threshold, tissue_mask = F.detect_tissue(image) metric_fn = PreprocessMetrics(threshold) results = metric_fn(image) Methods __call__ ( image , tissue_threshold ) (dict(str: float)) \u2014 Calculate preprocessing metrics for an image, method __call__ ( image , tissue_threshold ) Calculate preprocessing metrics for an image, Parameters image (ndarray or Image) \u2014 Input image. threshold \u2014 Tissue detection threshold for the tile images. Otsu's method cannot not be used here as some of the tiles may not contain background, and the method would still find an \"optimal\" threshold and classify tissue as background. Returns (dict(str: float)) Preprocessing metrics. function arr2pil ( image , equalize=False ) Convert numpy array to a Pillow image. Parameters image (ndarray or Image) \u2014 Image array. equalize (bool, optional) \u2014 Equalise image, useful for plotting masks. Returns (Image) Pillow image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") tissue_mask = F.detect_tissue(image) # Create nice mask image for visualization. tissue_mask_pil = F.arr2pil(1 - tissue_mask, equalize=True) function channel_quantiles ( image , tissue_mask=None , quantiles=[0.05, 0.1, 0.5, 0.9, 0.95] ) Calculate image channel quantiles which is useful in the detection of artifacts and shitty images. If the input image is RGB, HSV quantiles are also automatically calculated. Parameters image (ndarray or Image) \u2014 Input image. tissue_mask (ndarray, optional) \u2014 Tissue mask for the input image. Helpful for discarding background in quantile evaluation. Defaults to None. quantiles (list of float, optional) \u2014 Quantiles to be collected. Defaults to [0.05, 0.1, 0.5, 0.9, 0.95]. Returns (dict(str: list of int)) Quantiles for each image channel. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") results = F.channel_quantiles(image) function channel_std ( image ) Calculate standard deviation in each image channel. If the image is grayscale, only the total standard deviation is returned. Else both RGB and HSV channel standard deviations are evaluated. Parameters image (ndarray or Image) \u2014 Input image. Returns (dict(str: float)) Channel standard deviations. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") channel_std = F.channel_std(image) function data_loss ( image ) Calculates the percentage of completely white and black pixels. Parameters image (ndarray or Image) \u2014 Input image. Returns (dict(str: float)) Percentages of completely black (0) and white (255) pixels. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") black_pixels, white_pixels = F.data_loss(image).values() function dearray ( tissue_mask , kernel_size=5 , iterations=3 , min_area=0.1 , max_area=3.0 ) \u2192 (ndarray, (int, int, int, int), list of int) Detects TMA spots from an image and gives each spot a number starting from the top-left corner. Parameters tissue_mask (ndarray) \u2014 Tissue mask. kernel_size (int, optional) \u2014 Kernel size for dilate. Defaults to 5. iterations (int, optional) \u2014 Dilate iterations. Defaults to 3. min_area (float, optional) \u2014 Minimum area for a spot. Defaults to 0.1 and calculated with: median(areas) * min_area function detect_tissue ( image , threshold=None , multiplier=1.0 , sigma=1.0 , remove_white=False ) Detect tissue from image. Parameters image (ndarray or Image) \u2014 Input image. threshold (int, optional) \u2014 Threshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with multiplier . Used only if threshold is None. Defaults to 1.0. sigma (float, optional) \u2014 Sigma for gaussian blurring. Defaults to 1.0. remove_white (bool, optional) \u2014 Does not consider white pixels with Otsu's method. Useful for slide images where large areas are artificially set to white. Defaults to False. Returns (ndarray) Binary mask with 0=background and 1=tissue. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") tissue_mask = F.detect_tissue(image) function downsample_image ( image , max_dimension=2048 , return_arr=False ) Donwsaple image until one of the dimensions is less than max_dimension . Parameters image (ndarray or Image) \u2014 Image to be downsampled. max_dimension (int, optional) \u2014 Maximum dimension size. Defaults to 2048. Returns (Image or ndarray) Downsampled image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") downsampled = F.downsample_image(image, max_dimension=32) assert all(x<=32 for x in downsampled.size) function filter_coordinates ( coordinates , tissue_mask , max_background=0.95 , downsample=1.0 ) Filter a list of coordinates based on the amount of background. Parameters coordinates (list of (int, int, int)) \u2014 List of coordinates in XYWH format. max_background (float, optional) \u2014 Maximum amount of background in tile. Defaults to 0.95. downsample (Union(float, (float, float)), optional) \u2014 Downsample of the tissue mask. Defaults to 1. mask \u2014 Tissue mask. Returns (list of (int, int, int, int, float)) Filtered list of coordinates. Example import histoprep.functional as F from histoprep.helpers import read_image # Read image and extract tile coordinates. image = read_image(\"path/to/image.jpeg\") coordinates = F.tile_coordinates( dimensions=image.size, width=512, overlap=0.25, ) # Detect tissue. tissue_mask = F.detect_tissue(image) # Filter coordinates based on the amount of background. filtered_coordinates = F.filter_coordinates( coordinates=coordinates, tissue_mask=tissue_mask, max_background=0.9, ) function resize_image ( image , shape , return_arr=False , fast_resize=False ) Resize image to desired shape. Parameters image (Image or ndarray) \u2014 Input image. shape (int or (int)) \u2014 Shape of the output image. If shape is an integer then the image is resized to a square of (shape, shape). return_arr (bool, optional) \u2014 Return array. Defaults to False. fast_resize (bool, optional) \u2014 Uses nearest neigbour interpolation. Defaults to False. Returns (Image or ndarray) Resized image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") resized_32 = F.resize_image(image, (32, 32)) resized_32 = F.resize_image(image, 32) resized_32_arr = F.resize_image(image, 32, return_arr=True) function rgb2gray ( image ) Convert an RGB image to grayscale. Parameters image (ndarray or Image) \u2014 RGB image. Returns (ndarray or Image) Grayscale image. function rgb2hsv ( image ) Convert an RGB image to HSV. Parameters image (ndarray or Image) \u2014 RGB image. Returns (ndarray or Image) HSV image. function sharpness ( image , reduce='max' ) The method takes five crops from the image and calculates the standard deviation of the crops after a Laplace transformation. These values then reduced with the selected method. Parameters image (ndarray or Image) \u2014 Input image. reduction \u2014 Reduction method(s) for the Laplacian variance values for each crop. Defaults to \"max\". Returns (dict(str: float)) Reduced laplacian standard deviation of the crops. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") sharpness = F.sharpness(image, \"median\") function tile_coordinates ( dimensions , width , height=None , overlap=0.0 ) Extract a list of tile coordinates based on image dimensions. Parameters dimensions (int, int) \u2014 Image dimensions (height, width). width (int) \u2014 Width of a tile. height (int, optional) \u2014 Height of a tile. If None, will be set to width. Defaults to None. overlap (float, optional) \u2014 Overlap between neighbouring tiles. Defaults to 0.0. Returns (list of (int, int, int, int)) Tile coordinates in XYWH format. Example import histoprep.functional as F from histoprep.helpers import read_image # Read image and extract tile coordinates. image = read_image(\"path/to/image.jpeg\") coordinates = F.tile_coordinates( dimensions=image.size, width=512, overlap=0.25, ) package helpers function combine_metadata ( parent_dir , filename='tile_metadata.csv' ) Combine metadata under parent_dir into a single dataframe. Parameters parent_dir (str) \u2014 Output directory with the processed slides. filename (str, optional) \u2014 Filename to match. Defaults to \"tile_metadata.csv\". Raises IOError \u2014 Parent directory does not exist. NotADirectoryError \u2014 Parent directory is not a directory. Returns (pandas.DataFrame) Combined metadata. Example: ```python from histoprep.helpers import combine_metadata metadata = combine_metadata(\"/output/dir\") ``` generator multiprocess_loop ( func , iterable , num_workers=None , initializer=None , initializer_args=() , use_imap=True , **kwargs ) Maps function and iteration with multiple workers and yields the outputs. Parameters func \u2014 Function to be called on each list item. iterable \u2014 Iterable passed to the function. num_workers (int, optional) \u2014 Number of worker processes. If None, set to the number of CPU cores. Defaults to None. initializer (optional) \u2014 Initializer function for each worker process. Defaults to None. initializer_args (any), optional \u2014 : Arguments for the initializer function. Defaults to (). use_imap (bool, optional) \u2014 Uses imap instead of map. Imap returns results in the same order but is slightly slower to start up. Defaults to True. **kwargs \u2014 Passed to the func . Return: Iterable of function outputs. Example from histoprep.helpers import multiprocess_loop, read_image, progress_bar tiles = [] for tile in multiprocess_loop( func=read_image, iterable=paths, num_workers=20, return_arr=True # <- This is a keyword argument for read_image! ): tiles.append(tile) generator progress_bar ( iterable , total=None , desc=None , log_interval=1 , log_values=False , suppress=False ) Simple print-based progress bar. Parameters iterable \u2014 Iterable to wrap. total (int, optional) \u2014 Total steps. Defaults to None. desc (str, optional) \u2014 Description for progress bar. Defaults to None. log_interval (int, optional) \u2014 Log every n steps. Defaults to 1. log_values (bool, optional) \u2014 Returns (dict, next(iterable)), where values added to the dict are logged to the progress bar. Defaults to True. suppress (bool, optional) \u2014 Suppress all output. Defaults to False. Yields Iterable output function random_tile_collage ( paths , nrows=16 , ncols=32 , px=32 ) Plot random selection of the given paths. Parameters paths (Union(list of str, series, ndarray)) \u2014 Image paths. nrows (int, optional) \u2014 Number of rows in collage. Defaults to 16. ncols (int, optional) \u2014 Number of columns in collage. Defaults to 32. px (int, optional) \u2014 Size of each tile in collage. Defaults to 32. Returns (Image) Collage image of random tiles. Example import matplotlib.pyplot as plt from histoprep.helpers import random_tile_collage, combine_metadata # Load metadata. metadata = combine_metadata(\"/output_dir/\") data_loss_paths = metadata[\"black_pixels\" > 0.05][\"path\"] # Plot some tiles with data loss. plt.imshow(random_tile_collage(data_loss_paths)) function read_image ( path , return_arr=False ) Read image. Parameters path (str) \u2014 Path to image return_arr (bool, optional) \u2014 Return array instead of PIL image. Defaults to False. Returns (Image or ndarray) Image from path. Example from histoprep.helpers import read_image image = read_image(\"path/to/image\") arr = read_image(\"path/to/image\", return_arr=True) function remove_directory ( dir_path ) Remove directory and all files. Parameters dir_path (str) \u2014 Directory to be removed. Example from histoprep.helpers import remove_dir remove_dir(\"/shitty/slide/output_dir\") function rename_paths ( parent_dir ) Finds all metadata files inside parent_dir and updates the path column to match the current directory. Useful if you rename/move around the directories with the processed data. Parameters parent_dir (str) \u2014 Output directory with the processed slides. Returns (list of (str, Exception)) List csv-paths and Exceptions, for the dataframes which could not be updated. Example: ```python from histoprep.helpers import rename_paths failures = rename_paths(\"/new/output/dir\") ``` function strip_metric_colums ( metadata ) Remove columns with preprocessing metrics. Parameters metadata (DataFrame) \u2014 Tile metadata. Returns (DataFrame) Tile metadata without preprocessing metrics. Example from histoprep.helpers import combine_metadata, strip_metric_colums metadata = combine_metadata(\"/output/dir\") tile_info = strip_metric_columns(metadata)","title":"histoprep"},{"location":"api/#histoprep","text":"class","title":"histoprep"},{"location":"api/#histoprep_reader_readerslidereader","text":"Reader for large slide images with extended functionality such as tissue detection, tile coordinate extraction, dearraying TMA spots and saving tiles. Parameters path (str) \u2014 Path to slide image. verbose (bool, optional) \u2014 Set to True to get verbose output. Defaults to False. preferred_dimension (int, optional) \u2014 Preferred maximum dimension for the for the generated thumbnail. Defaults to 4096. threshold (int, optional) \u2014 Treshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. threshold_multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with threshold_multiplier . Used only if threshold is None. Defaults to 1.05. max_dimension (int, optional) \u2014 Maximum dimension for the generated thumbnail. Smaller thumbnails are preferred, but in the absence of these, the first level with all dimensions less than max_dimension is chosen. Defaults to 16_384. Attributes annotated_thumbnail_spots (Image) \u2014 Thumbnail image annotated with the spot coordinates. annotated_thumbnail_tiles (Image) \u2014 Thumbnail image annotated with the tile coordinates. dimensions (int, int) \u2014 Slide image dimensions. level_dimensions (dict(int: (int, int))) \u2014 Downsamples for each level. level_downsamples (dict(int: (float, float))) \u2014 Dimensions for each level. spot_mask (Image) \u2014 TMA spot mask (0=background, 1=spot). spot_metadata (Image) \u2014 Metadata for TMA spots. thumbnail (Image) \u2014 Thumbnail image of the slide. thumbnail_downsample (Image) \u2014 Downsample for the thumbnail image. tile_metadata (Image) \u2014 Metadata for saved tiles. tissue_mask (Image) \u2014 Tissue mask (0=background, 1=tissue). tissue_threshold (int) \u2014 Threshold for tissue detection. Raises FileNotFoundError \u2014 File not found. IOError \u2014 File not readable by HistoPrep. NotADirectoryError \u2014 Scratch directory exists, but isn't a directory. Usage: from histoprep import SlideReader # Load tile images. reader = SlideReader(\"/path/to/slide.tiff\") thumbnail = reader.get_thumbnail() thresh, tissue_mask = reader.detect_tissue() coords = reader.get_tile_coordinates( width=512, overlap=0.1, tissue_mask=tissue_mask ) tiles = [reader.read_region(xywh) for xywh in coords] Methods dearray ( kernel_size , iterations , min_area , max_area ) (DataFrame) \u2014 Dearray TMA spots. detect_tissue ( threshold , multiplier , sigma , remove_white ) \u2014 Detect tissue from slide image. get_thumbnail ( preferred_dimension , level , return_arr , fill , return_level ) (ndarray or Image) \u2014 Get thumbnail image of the slide. get_tile_coordinates ( width , overlap , height , level , tissue_mask , max_background ) (list of (int, int, int, int)) \u2014 Get tile coordinates for the slide. read_region ( xywh , level , return_arr , fill ) (Image or ndarray) \u2014 Read region from slide. save_spots ( output_dir , overwrite , image_format , quality , num_workers , num_retries , display_progress ) (DataFrame) \u2014 Save TMA spot images from a slide. save_tiles ( output_dir , coordinates , level , preprocess_metrics , overwrite , image_format , quality , num_workers , num_retries , display_progress ) \u2014 Save tile images from a slide. method","title":"histoprep._reader._reader.SlideReader"},{"location":"api/#histoprep_reader_readerslidereaderread_region","text":"Read region from slide. Parameters xywh (int, int, int, int) \u2014 Region defined by X, Y, width and height. return_arr (bool, optional) \u2014 Return region as an uint8 array instead of a Pil image. Defaults to False. fill (int, optional) \u2014 Fill overbound areas with this value. If None, raises an error when the region goes out of bounds. Defaults to 255. Raises ValueError \u2014 XYWH, level or fill are not integers. ValueError \u2014 Negative coordinates. ValueError \u2014 Width or height less than 1. ValueError \u2014 Region overbound without a fill value. Returns (Image or ndarray) Image of the region. Example from histoprep import SlideReader slide = SlideReader(\"/path/to/slide.tiff\") tile_image = slide.read_region(x=0, y=0, w=1024, h=1024) method","title":"histoprep._reader._reader.SlideReader.read_region"},{"location":"api/#histoprep_reader_readerslidereaderget_thumbnail","text":"Get thumbnail image of the slide. Running this method updates the thumbnail attribute. Parameters preferred_dimension (int, optional) \u2014 Selects the first level which has both dimensions smaller than preferred_dimension . If not found, selects the smallest thumbnail with all dimensions less than MAX_DIMENSION attribute. Defaults to 4096. level (int, optional) \u2014 Overwrites max_dimension and loads a specific level. Defaults to None. return_arr (bool, optional) \u2014 Return an uint8 array instead of PIL Image. Defaults to False. fill (int, optional) \u2014 Fill out of bounds regions. Defaults to 255. return_level (bool, optional) \u2014 Return the thumbnail level. Defaults to False. Raises ValueError \u2014 No levels with dimensions less than MAX_DIMENSION . ValueError \u2014 Level does not exist. Returns (ndarray or Image) Thumbnail image. Example from histoprep import SlideReader reader = Slidereader(\"/path/to/slide.tiff\") thumbnail = reader.get_thumbnail() method","title":"histoprep._reader._reader.SlideReader.get_thumbnail"},{"location":"api/#histoprep_reader_readerslidereaderdetect_tissue","text":"Detect tissue from slide image. Running this method updates the tissue_mask attribute. Parameters threshold (int, optional) \u2014 Treshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with multiplier . Used only if threshold is None. Defaults to 1.0. sigma (float, optional) \u2014 Sigma for gaussian blurring. Defaults to 1.05. remove_white (bool, optional) \u2014 Changes completely white regions to the second highest pixel value, before detecting background. This way Otsu's method isn't affected by possibly extreme white areas. Defaults to True. Returns Binary mask with 0=background and 1=tissue. Example from histoprep import SlideReader reader = SlideReader(\"path/to/slide\") thresh, tissue_mask = reader.detect_tissue() method","title":"histoprep._reader._reader.SlideReader.detect_tissue"},{"location":"api/#histoprep_reader_readerslidereaderget_tile_coordinates","text":"Get tile coordinates for the slide. Divides the slide into tiles based on width, height and overlap. These tiles are then filtered based on the amount of background. Running this method updates the annotated_thumbnail_tiles attribute. Parameters width (int) \u2014 Tile width. overlap (float, optional) \u2014 Overlap between neighbouring tiles. Defaults to 0.0. height (int, optional) \u2014 Height of a tile. If None, will be set to width. Defaults to None. level (int, optional) \u2014 Slide level for calculating tile coordinates. Defaults to 0. tissue_mask (ndarray, optional) \u2014 Tissue mask. If None, uses a cached tissue mask. Defaults to None. max_background (float, optional) \u2014 Maximum amount of background in tile. Defaults to 0.95. Returns (list of (int, int, int, int)) XYWH coordinates for each tile. method","title":"histoprep._reader._reader.SlideReader.get_tile_coordinates"},{"location":"api/#histoprep_reader_readerslidereaderdearray","text":"Dearray TMA spots. Running this method updates the annotated_thumbnail_spots and spot_mask attributes. Parameters kernel_size (int, optional) \u2014 Kernel size for dilate. Defaults to 5. iterations (int, optional) \u2014 Dilate iterations. Defaults to 3. min_area (float, optional) \u2014 Minimum area for a spot. Defaults to 0.1 and calculated with: median(areas) * min_area max_area (float, optional) \u2014 Maximum area for a spot. Similar to min_area. Defaults to 3.0. Returns (DataFrame) Spot metadata. method","title":"histoprep._reader._reader.SlideReader.dearray"},{"location":"api/#histoprep_reader_readerslidereadersave_spots","text":"Save TMA spot images from a slide. Parameters output_dir (str) \u2014 Output directory for the processed images. overwrite (bool, optional) \u2014 Overwrite any existing images. Defaults to False. image_format (str, optional) \u2014 Image format. Defaults to \"jpeg\". quality (int, optional) \u2014 Quality of JPEG compression. Defaults to 95. num_workers (int, optional) \u2014 Number of image saving workers. Defaults to the number of CPU cores. num_retries (int, optional) \u2014 Number retries loading any regions, which couldn't be saved the first time. Defaults to 10. display_progress (bool, optional) \u2014 Display progress bar. Defaults to True. Returns (DataFrame) Dataframe with spot bounding boxes. method","title":"histoprep._reader._reader.SlideReader.save_spots"},{"location":"api/#histoprep_reader_readerslidereadersave_tiles","text":"Save tile images from a slide. Parameters output_dir (str) \u2014 Output directory for the processed images. coordinates (list of (int, int, int, int)) \u2014 A list of XYWH coordinates for the tile regions. Can be easily created with the SlideReader.get_tile_coordinates() method. Please note that the level used to create coordinates should, match the level argument for this function. level (int, optional) \u2014 Slide level to read tile images from. This should match the level used to create the coordinates! Defaults to 0. preprocess_metrics (optional) \u2014 Any Callable which takes an image as an input and returns a dictionary. It is recommended to use the histoprep.PreprocessMetrics class, which can be modified with custom functions. Defaults to histoprep.PreprocessMetrics() . overwrite (bool, optional) \u2014 Overwrite any existing images. Defaults to False. image_format (str, optional) \u2014 Image format. Defaults to \"jpeg\". quality (int, optional) \u2014 Quality of JPEG compression. Defaults to 95. num_workers (int, optional) \u2014 Number of image saving workers. Defaults to the number of CPU cores. num_retries (int, optional) \u2014 Number retries loading any regions, which couldn't be saved the first time. Defaults to 10. display_progress (bool, optional) \u2014 Display progress bar. Defaults to True. Returns Tile metadata and preprocessing metrics. class","title":"histoprep._reader._reader.SlideReader.save_tiles"},{"location":"api/#histoprep_outliers_detectoutlierdetector","text":"Automatic outlier detection from color channel quantile metrics. Kmeans++ is used to cluster each tile into the desired number of clusters. Clusters are ordered by the distance to the origo in decreasing order, and thus the most likely outlier group is first and last groups contain normal images. Parameters metadata (DataFrame) \u2014 Metadata containing columns: [channel_name]_q={quantile} num_clusters (int, optional) \u2014 Number of clusters. Defaults to 20. batch_size (int, optional) \u2014 Batch size for kmeans++. Defaults to 2**14. Attributes cluster_counts (ndarray) \u2014 Number of members in each cluster. cluster_distances (ndarray) \u2014 Cluster mean euclidean distance to the origo. clusters (ndarray) \u2014 Cluster assignments. metrics (ndarray) \u2014 Quantile metrics normalised with: (X - X.mean(0)) / X.std(0) Example import histoprep detector = histoprep.OutlierDetector(metadata, num_clusters=20) detect.plot_clusters(min_distance=10) # From the plots we might see that clusters 0-3 contain outliers. metadata[\"outlier\"] = False metadata.loc[detector.clusters < 4, \"outlier\"] = True Methods pca_representation ( num_components , max_samples , **kwargs ) (ndarray, ndarray) \u2014 Run princical component analysis (PCA) to get a representation of metrics. Does not produce as nice results as UMAP, but it's faster and supported out-of-the-box. plot_cluster ( cluster , num_examples , ncols , px , figsize ) \u2014 Plot example images from a single cluster. plot_clusters ( min_distance , num_examples , ncols , px , figsize ) \u2014 Plot example images from clusters. plot_representation ( coordinates , indices , label_clusters , size , cmap , figsize ) \u2014 Plot representation of metrics. umap_representation ( num_components , num_neighbors , metric , max_samples , verbose , **kwargs ) (ndarray, ndarray) \u2014 Run Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction. method","title":"histoprep._outliers._detect.OutlierDetector"},{"location":"api/#histoprep_outliers_detectoutlierdetectorplot_clusters","text":"Plot example images from clusters. Parameters min_distance (int, optional) \u2014 Minimum distance to filter which groups to plot. Defaults to None. num_examples (int, optional) \u2014 Number of example images from each group. Defaults to 256. ncols (int, optional) \u2014 Number of columns for plotting example images. Defaults to 32. px (int, optional) \u2014 Size of each example image. Defaults to 64. figsize (float, float), optional \u2014 Figure size for plotting. Defaults to (default_width * 1.5, default_height) method","title":"histoprep._outliers._detect.OutlierDetector.plot_clusters"},{"location":"api/#histoprep_outliers_detectoutlierdetectorplot_cluster","text":"Plot example images from a single cluster. Parameters cluster (int, optional) \u2014 Cluster number. Defaults to 0. num_examples (int, optional) \u2014 Number of example images from each group. Defaults to 256. ncols (int, optional) \u2014 Number of columns for plotting example images. Defaults to 32. px (int, optional) \u2014 Size of each example image. Defaults to 64. figsize (float, float), optional \u2014 Figure size for plotting. Defaults to (default_width * 1.5, default_height) method","title":"histoprep._outliers._detect.OutlierDetector.plot_cluster"},{"location":"api/#histoprep_outliers_detectoutlierdetectorumap_representation","text":"Run Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction. Parameters num_components (int, optional) \u2014 Number of components, two offers easy visualisation. Defaults to 2. num_neighbors (int, optional) \u2014 Number of neighbours, should be between 2-100. Defaults to 15. max_samples (int, optional) \u2014 UMAP does not handle very large sample sizes well. Increase if you want to go and get coffee. Defaults to 100_000. **kwargs \u2014 Any keyword arguments for umap.UMAP . Returns (ndarray, ndarray) UMAP representation and indices of the selected samples method","title":"histoprep._outliers._detect.OutlierDetector.umap_representation"},{"location":"api/#histoprep_outliers_detectoutlierdetectorpca_representation","text":"Run princical component analysis (PCA) to get a representation of metrics. Does not produce as nice results as UMAP, but it's faster and supported out-of-the-box. Parameters num_components (int, optional) \u2014 Number of components, two offers easy visualisation. Defaults to 2. max_samples (int, optional) \u2014 PCA does handle very large sample sizes well, but this argument can be used to limit the number of samples. Defaults to 1_000_000. **kwargs \u2014 Any keyword arguments for sklearn.decomposition.PCA . Returns (ndarray, ndarray) PCA representation and indices of the selected samples method","title":"histoprep._outliers._detect.OutlierDetector.pca_representation"},{"location":"api/#histoprep_outliers_detectoutlierdetectorplot_representation","text":"Plot representation of metrics. Parameters coordinates (ndarray) \u2014 Representation coordinates. indices (ndarray) \u2014 Sample indices returned by {umap, pca}_representation . size (float, optional) \u2014 Size of each dot. Defaults to 0.5. cmap (str, optional) \u2014 Colour map. Defaults to \"plasma\" for distance and \"coolwarm_r\" for clusters. figsize (float, float), optional \u2014 Figure size. Defaults to Defaults to (default_width * 1.5, default_height * 1.5). label_clusers \u2014 Label each cluster in the plot instead of log(distance). class","title":"histoprep._outliers._detect.OutlierDetector.plot_representation"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizer","text":"Visualise preprocessing metrics to identify outliers. Plotting might take a while if metadata contains several million samples. Parameters metadata (DataFrame) \u2014 Metadata with preprocessing metrics. Example import histoprep # Initialize class. visualise = histoprep.OutlierVisualizer(metadata) # Lets visualise tiles with data loss... visualise.plot_histogram_with_examples(column=\"black_pixels\") # ... or with too much background ... visualise.plot_histogram_with_examples(column=\"background\") # ... or if the colour channel variances picked up any outlies. visualise.plot_rgb_std(log_scale=True) visualise.plot_hsv_std(log_scale=True) Methods plot_histogram_with_examples ( column , bins , num_examples , log_scale , figsize ) \u2014 Plot a histogram of column values, with example tiles from each bin. plot_hsv_mean ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of HSV channels for each tile. plot_hsv_quantiles ( bins , log_scale , figsize ) \u2014 Plot the quantile values of RGB channels for each tile. plot_hsv_std ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of HSV channels for each tile. plot_rgb_mean ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of RGB (and gray) channels for each tile. plot_rgb_quantiles ( bins , log_scale , figsize ) \u2014 Plot the quantile values of RGB channels for each tile. plot_rgb_std ( bins , log_scale , figsize ) \u2014 Plot the standard deviation of RGB (and gray) channels for each tile. method","title":"histoprep._outliers._visualize.OutlierVisualizer"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_rgb_mean","text":"Plot the standard deviation of RGB (and gray) channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_rgb_mean"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_rgb_std","text":"Plot the standard deviation of RGB (and gray) channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_rgb_std"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_hsv_mean","text":"Plot the standard deviation of HSV channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 1.5, default_h). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_hsv_mean"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_hsv_std","text":"Plot the standard deviation of HSV channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 1.5, default_h). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_hsv_std"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_rgb_quantiles","text":"Plot the quantile values of RGB channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_rgb_quantiles"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_hsv_quantiles","text":"Plot the quantile values of RGB channels for each tile. Parameters bins (int, optional) \u2014 Number of bins. Defaults to 50. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to False. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). method","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_hsv_quantiles"},{"location":"api/#histoprep_outliers_visualizeoutliervisualizerplot_histogram_with_examples","text":"Plot a histogram of column values, with example tiles from each bin. Parameters column (str) \u2014 Name of the column to plot. bins (int, optional) \u2014 Number of bins. Defaults to 30. num_examples (int, optional) \u2014 Number of example images per bin. Defaults to 16. log_scale (bool, optional) \u2014 Set y-axis to logarithmic scale. Defaults to True. figsize (float, float), optional \u2014 Figure size. Defaults to (default_w * 2, default_h * 2). package","title":"histoprep._outliers._visualize.OutlierVisualizer.plot_histogram_with_examples"},{"location":"api/#histoprepfunctional","text":"class","title":"histoprep.functional"},{"location":"api/#histoprepfunctional_preprocesspreprocessmetrics","text":"Class to calculate basic preprocessing metrics for a histological image. Parameters channel_resize (int, optional) \u2014 Image size for F.channel_quantiles() . Defaults to 128. quantiles (list of int, optional) \u2014 RGB and HSV quantiles. Defaults to [0.05, 0.1, 0.5, 0.9, 0.95]. sharpness_reduce (str or list, optional) \u2014 Sharpness reduction method. Defaults to \"max\". custom_callback (optional) \u2014 Custom callback for to calculate new metrics. Defaults to None. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") threshold, tissue_mask = F.detect_tissue(image) metric_fn = PreprocessMetrics(threshold) results = metric_fn(image) Methods __call__ ( image , tissue_threshold ) (dict(str: float)) \u2014 Calculate preprocessing metrics for an image, method","title":"histoprep.functional._preprocess.PreprocessMetrics"},{"location":"api/#histoprepfunctional_preprocesspreprocessmetricscall","text":"Calculate preprocessing metrics for an image, Parameters image (ndarray or Image) \u2014 Input image. threshold \u2014 Tissue detection threshold for the tile images. Otsu's method cannot not be used here as some of the tiles may not contain background, and the method would still find an \"optimal\" threshold and classify tissue as background. Returns (dict(str: float)) Preprocessing metrics. function","title":"histoprep.functional._preprocess.PreprocessMetrics.call"},{"location":"api/#histoprepfunctional_helpersarr2pil","text":"Convert numpy array to a Pillow image. Parameters image (ndarray or Image) \u2014 Image array. equalize (bool, optional) \u2014 Equalise image, useful for plotting masks. Returns (Image) Pillow image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") tissue_mask = F.detect_tissue(image) # Create nice mask image for visualization. tissue_mask_pil = F.arr2pil(1 - tissue_mask, equalize=True) function","title":"histoprep.functional._helpers.arr2pil"},{"location":"api/#histoprepfunctional_preprocesschannel_quantiles","text":"Calculate image channel quantiles which is useful in the detection of artifacts and shitty images. If the input image is RGB, HSV quantiles are also automatically calculated. Parameters image (ndarray or Image) \u2014 Input image. tissue_mask (ndarray, optional) \u2014 Tissue mask for the input image. Helpful for discarding background in quantile evaluation. Defaults to None. quantiles (list of float, optional) \u2014 Quantiles to be collected. Defaults to [0.05, 0.1, 0.5, 0.9, 0.95]. Returns (dict(str: list of int)) Quantiles for each image channel. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") results = F.channel_quantiles(image) function","title":"histoprep.functional._preprocess.channel_quantiles"},{"location":"api/#histoprepfunctional_preprocesschannel_std","text":"Calculate standard deviation in each image channel. If the image is grayscale, only the total standard deviation is returned. Else both RGB and HSV channel standard deviations are evaluated. Parameters image (ndarray or Image) \u2014 Input image. Returns (dict(str: float)) Channel standard deviations. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") channel_std = F.channel_std(image) function","title":"histoprep.functional._preprocess.channel_std"},{"location":"api/#histoprepfunctional_preprocessdata_loss","text":"Calculates the percentage of completely white and black pixels. Parameters image (ndarray or Image) \u2014 Input image. Returns (dict(str: float)) Percentages of completely black (0) and white (255) pixels. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") black_pixels, white_pixels = F.data_loss(image).values() function","title":"histoprep.functional._preprocess.data_loss"},{"location":"api/#histoprepfunctional_dearraydearray","text":"Detects TMA spots from an image and gives each spot a number starting from the top-left corner. Parameters tissue_mask (ndarray) \u2014 Tissue mask. kernel_size (int, optional) \u2014 Kernel size for dilate. Defaults to 5. iterations (int, optional) \u2014 Dilate iterations. Defaults to 3. min_area (float, optional) \u2014 Minimum area for a spot. Defaults to 0.1 and calculated with: median(areas) * min_area function","title":"histoprep.functional._dearray.dearray"},{"location":"api/#histoprepfunctional_tissuedetect_tissue","text":"Detect tissue from image. Parameters image (ndarray or Image) \u2014 Input image. threshold (int, optional) \u2014 Threshold for tissue detection. If set, will detect tissue by global thresholding, and otherwise Otsu's method is used to find a threshold. Defaults to None. multiplier (float, optional) \u2014 Otsu's method is used to find an optimal threshold by minimizing the weighted within-class variance. This threshold is then multiplied with multiplier . Used only if threshold is None. Defaults to 1.0. sigma (float, optional) \u2014 Sigma for gaussian blurring. Defaults to 1.0. remove_white (bool, optional) \u2014 Does not consider white pixels with Otsu's method. Useful for slide images where large areas are artificially set to white. Defaults to False. Returns (ndarray) Binary mask with 0=background and 1=tissue. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") tissue_mask = F.detect_tissue(image) function","title":"histoprep.functional._tissue.detect_tissue"},{"location":"api/#histoprepfunctional_helpersdownsample_image","text":"Donwsaple image until one of the dimensions is less than max_dimension . Parameters image (ndarray or Image) \u2014 Image to be downsampled. max_dimension (int, optional) \u2014 Maximum dimension size. Defaults to 2048. Returns (Image or ndarray) Downsampled image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") downsampled = F.downsample_image(image, max_dimension=32) assert all(x<=32 for x in downsampled.size) function","title":"histoprep.functional._helpers.downsample_image"},{"location":"api/#histoprepfunctional_coordinatesfilter_coordinates","text":"Filter a list of coordinates based on the amount of background. Parameters coordinates (list of (int, int, int)) \u2014 List of coordinates in XYWH format. max_background (float, optional) \u2014 Maximum amount of background in tile. Defaults to 0.95. downsample (Union(float, (float, float)), optional) \u2014 Downsample of the tissue mask. Defaults to 1. mask \u2014 Tissue mask. Returns (list of (int, int, int, int, float)) Filtered list of coordinates. Example import histoprep.functional as F from histoprep.helpers import read_image # Read image and extract tile coordinates. image = read_image(\"path/to/image.jpeg\") coordinates = F.tile_coordinates( dimensions=image.size, width=512, overlap=0.25, ) # Detect tissue. tissue_mask = F.detect_tissue(image) # Filter coordinates based on the amount of background. filtered_coordinates = F.filter_coordinates( coordinates=coordinates, tissue_mask=tissue_mask, max_background=0.9, ) function","title":"histoprep.functional._coordinates.filter_coordinates"},{"location":"api/#histoprepfunctional_helpersresize_image","text":"Resize image to desired shape. Parameters image (Image or ndarray) \u2014 Input image. shape (int or (int)) \u2014 Shape of the output image. If shape is an integer then the image is resized to a square of (shape, shape). return_arr (bool, optional) \u2014 Return array. Defaults to False. fast_resize (bool, optional) \u2014 Uses nearest neigbour interpolation. Defaults to False. Returns (Image or ndarray) Resized image. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") resized_32 = F.resize_image(image, (32, 32)) resized_32 = F.resize_image(image, 32) resized_32_arr = F.resize_image(image, 32, return_arr=True) function","title":"histoprep.functional._helpers.resize_image"},{"location":"api/#histoprepfunctional_helpersrgb2gray","text":"Convert an RGB image to grayscale. Parameters image (ndarray or Image) \u2014 RGB image. Returns (ndarray or Image) Grayscale image. function","title":"histoprep.functional._helpers.rgb2gray"},{"location":"api/#histoprepfunctional_helpersrgb2hsv","text":"Convert an RGB image to HSV. Parameters image (ndarray or Image) \u2014 RGB image. Returns (ndarray or Image) HSV image. function","title":"histoprep.functional._helpers.rgb2hsv"},{"location":"api/#histoprepfunctional_preprocesssharpness","text":"The method takes five crops from the image and calculates the standard deviation of the crops after a Laplace transformation. These values then reduced with the selected method. Parameters image (ndarray or Image) \u2014 Input image. reduction \u2014 Reduction method(s) for the Laplacian variance values for each crop. Defaults to \"max\". Returns (dict(str: float)) Reduced laplacian standard deviation of the crops. Example import histoprep.functional as F from histoprep.helpers import read_image image = read_image(\"path/to/image.jpeg\") sharpness = F.sharpness(image, \"median\") function","title":"histoprep.functional._preprocess.sharpness"},{"location":"api/#histoprepfunctional_coordinatestile_coordinates","text":"Extract a list of tile coordinates based on image dimensions. Parameters dimensions (int, int) \u2014 Image dimensions (height, width). width (int) \u2014 Width of a tile. height (int, optional) \u2014 Height of a tile. If None, will be set to width. Defaults to None. overlap (float, optional) \u2014 Overlap between neighbouring tiles. Defaults to 0.0. Returns (list of (int, int, int, int)) Tile coordinates in XYWH format. Example import histoprep.functional as F from histoprep.helpers import read_image # Read image and extract tile coordinates. image = read_image(\"path/to/image.jpeg\") coordinates = F.tile_coordinates( dimensions=image.size, width=512, overlap=0.25, ) package","title":"histoprep.functional._coordinates.tile_coordinates"},{"location":"api/#histoprephelpers","text":"function","title":"histoprep.helpers"},{"location":"api/#histoprephelpers_metadatacombine_metadata","text":"Combine metadata under parent_dir into a single dataframe. Parameters parent_dir (str) \u2014 Output directory with the processed slides. filename (str, optional) \u2014 Filename to match. Defaults to \"tile_metadata.csv\". Raises IOError \u2014 Parent directory does not exist. NotADirectoryError \u2014 Parent directory is not a directory. Returns (pandas.DataFrame) Combined metadata. Example: ```python from histoprep.helpers import combine_metadata metadata = combine_metadata(\"/output/dir\") ``` generator","title":"histoprep.helpers._metadata.combine_metadata"},{"location":"api/#histoprephelpers_multiprocessmultiprocess_loop","text":"Maps function and iteration with multiple workers and yields the outputs. Parameters func \u2014 Function to be called on each list item. iterable \u2014 Iterable passed to the function. num_workers (int, optional) \u2014 Number of worker processes. If None, set to the number of CPU cores. Defaults to None. initializer (optional) \u2014 Initializer function for each worker process. Defaults to None. initializer_args (any), optional \u2014 : Arguments for the initializer function. Defaults to (). use_imap (bool, optional) \u2014 Uses imap instead of map. Imap returns results in the same order but is slightly slower to start up. Defaults to True. **kwargs \u2014 Passed to the func . Return: Iterable of function outputs. Example from histoprep.helpers import multiprocess_loop, read_image, progress_bar tiles = [] for tile in multiprocess_loop( func=read_image, iterable=paths, num_workers=20, return_arr=True # <- This is a keyword argument for read_image! ): tiles.append(tile) generator","title":"histoprep.helpers._multiprocess.multiprocess_loop"},{"location":"api/#histoprephelpers_verboseprogress_bar","text":"Simple print-based progress bar. Parameters iterable \u2014 Iterable to wrap. total (int, optional) \u2014 Total steps. Defaults to None. desc (str, optional) \u2014 Description for progress bar. Defaults to None. log_interval (int, optional) \u2014 Log every n steps. Defaults to 1. log_values (bool, optional) \u2014 Returns (dict, next(iterable)), where values added to the dict are logged to the progress bar. Defaults to True. suppress (bool, optional) \u2014 Suppress all output. Defaults to False. Yields Iterable output function","title":"histoprep.helpers._verbose.progress_bar"},{"location":"api/#histoprephelpers_visualizerandom_tile_collage","text":"Plot random selection of the given paths. Parameters paths (Union(list of str, series, ndarray)) \u2014 Image paths. nrows (int, optional) \u2014 Number of rows in collage. Defaults to 16. ncols (int, optional) \u2014 Number of columns in collage. Defaults to 32. px (int, optional) \u2014 Size of each tile in collage. Defaults to 32. Returns (Image) Collage image of random tiles. Example import matplotlib.pyplot as plt from histoprep.helpers import random_tile_collage, combine_metadata # Load metadata. metadata = combine_metadata(\"/output_dir/\") data_loss_paths = metadata[\"black_pixels\" > 0.05][\"path\"] # Plot some tiles with data loss. plt.imshow(random_tile_collage(data_loss_paths)) function","title":"histoprep.helpers._visualize.random_tile_collage"},{"location":"api/#histoprephelpers_ioread_image","text":"Read image. Parameters path (str) \u2014 Path to image return_arr (bool, optional) \u2014 Return array instead of PIL image. Defaults to False. Returns (Image or ndarray) Image from path. Example from histoprep.helpers import read_image image = read_image(\"path/to/image\") arr = read_image(\"path/to/image\", return_arr=True) function","title":"histoprep.helpers._io.read_image"},{"location":"api/#histoprephelpers_filesremove_directory","text":"Remove directory and all files. Parameters dir_path (str) \u2014 Directory to be removed. Example from histoprep.helpers import remove_dir remove_dir(\"/shitty/slide/output_dir\") function","title":"histoprep.helpers._files.remove_directory"},{"location":"api/#histoprephelpers_metadatarename_paths","text":"Finds all metadata files inside parent_dir and updates the path column to match the current directory. Useful if you rename/move around the directories with the processed data. Parameters parent_dir (str) \u2014 Output directory with the processed slides. Returns (list of (str, Exception)) List csv-paths and Exceptions, for the dataframes which could not be updated. Example: ```python from histoprep.helpers import rename_paths failures = rename_paths(\"/new/output/dir\") ``` function","title":"histoprep.helpers._metadata.rename_paths"},{"location":"api/#histoprephelpers_metadatastrip_metric_colums","text":"Remove columns with preprocessing metrics. Parameters metadata (DataFrame) \u2014 Tile metadata. Returns (DataFrame) Tile metadata without preprocessing metrics. Example from histoprep.helpers import combine_metadata, strip_metric_colums metadata = combine_metadata(\"/output/dir\") tile_info = strip_metric_columns(metadata)","title":"histoprep.helpers._metadata.strip_metric_colums"},{"location":"about/citation/","text":"Citation If you use HistoPrep in a publication, please cite the github repository. @misc{histoprep2022, author = {Pohjonen J. and Ariotta. V}, title = {HistoPrep: Preprocessing large medical images for machine learning made easy!}, year = {2022}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/jopo666/HistoPrep}}, }","title":"Citation"},{"location":"about/citation/#citation","text":"If you use HistoPrep in a publication, please cite the github repository. @misc{histoprep2022, author = {Pohjonen J. and Ariotta. V}, title = {HistoPrep: Preprocessing large medical images for machine learning made easy!}, year = {2022}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\\url{https://github.com/jopo666/HistoPrep}}, }","title":"Citation"},{"location":"about/install/","text":"Install HistoPrep uses OpenSlide to read slide images, which unfortunately requires that the original C++ library is installed on your system. The installation instructions can be found here . Then you can simply run. pip install histoprep There is an annoying bug , which sometimes pops up when installing OpenSlide. This happens if OpenSlide is shipped with an old version of pixman library. There are three ways of fixing the problem .","title":"Install"},{"location":"about/install/#install","text":"HistoPrep uses OpenSlide to read slide images, which unfortunately requires that the original C++ library is installed on your system. The installation instructions can be found here . Then you can simply run. pip install histoprep There is an annoying bug , which sometimes pops up when installing OpenSlide. This happens if OpenSlide is shipped with an old version of pixman library. There are three ways of fixing the problem .","title":"Install"},{"location":"about/license/","text":"MIT License Copyright (c) 2022 Jopo666 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"about/license/#mit-license","text":"Copyright (c) 2022 Jopo666 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"about/release_notes/","text":"Release notes 1.0.8 Fix small edge case bugs. 1.0.7 Fix bug in SlideReader where, reading regions from levels other than zero returned the wrong region. 1.0.6 Fix bug in Pillow backend, where x and y axes were flipped. 1.0.5 Fix bug in HistoPrep executable. 1.0.4 Fix bug with progress_bar not returning a logging dictionary with suppress=True . 1.0.3 Remove warning due to large datasets in OutlierVisualiser and move it to __doc__ . 1.0.2 Fix bug in HistoPrep executable. 1.0.1 Fix dependency alerts (Pillow). 1.0.0 Complete refactoring of the HistoPrep module, thus almost all changes are breaking changes. Combined Cutter and Dearrayer into a single class SlideReader for processing slides. Remove Explore function and replace it with OutlierVisualizer . Add automatic outlier detection with OutlierDetector . Complete rehaul on the sub-modules. histoprep.functional All SlideReader functionality is implemented here, and thus individual parts such as detect_tissue , tile_coordinates , dearray , PreprocessMetrics etc. can be used individually. histoprep.helpers Helper functions such as multiprocess_loop , progress_bar , combine_metadata . Plotting random tiles with random_tile_collage . histoprep.preprocess module has been merged to histoprep.helpers . < 1.0.0 Non-production ready releases of HistoPrep.","title":"Release notes"},{"location":"about/release_notes/#release-notes","text":"","title":"Release notes"},{"location":"about/release_notes/#108","text":"Fix small edge case bugs.","title":"1.0.8"},{"location":"about/release_notes/#107","text":"Fix bug in SlideReader where, reading regions from levels other than zero returned the wrong region.","title":"1.0.7"},{"location":"about/release_notes/#106","text":"Fix bug in Pillow backend, where x and y axes were flipped.","title":"1.0.6"},{"location":"about/release_notes/#105","text":"Fix bug in HistoPrep executable.","title":"1.0.5"},{"location":"about/release_notes/#104","text":"Fix bug with progress_bar not returning a logging dictionary with suppress=True .","title":"1.0.4"},{"location":"about/release_notes/#103","text":"Remove warning due to large datasets in OutlierVisualiser and move it to __doc__ .","title":"1.0.3"},{"location":"about/release_notes/#102","text":"Fix bug in HistoPrep executable.","title":"1.0.2"},{"location":"about/release_notes/#101","text":"Fix dependency alerts (Pillow).","title":"1.0.1"},{"location":"about/release_notes/#100","text":"Complete refactoring of the HistoPrep module, thus almost all changes are breaking changes. Combined Cutter and Dearrayer into a single class SlideReader for processing slides. Remove Explore function and replace it with OutlierVisualizer . Add automatic outlier detection with OutlierDetector . Complete rehaul on the sub-modules. histoprep.functional All SlideReader functionality is implemented here, and thus individual parts such as detect_tissue , tile_coordinates , dearray , PreprocessMetrics etc. can be used individually. histoprep.helpers Helper functions such as multiprocess_loop , progress_bar , combine_metadata . Plotting random tiles with random_tile_collage . histoprep.preprocess module has been merged to histoprep.helpers .","title":"1.0.0"},{"location":"about/release_notes/#100_1","text":"Non-production ready releases of HistoPrep.","title":"&lt; 1.0.0"},{"location":"examples/cut_tiles/cut_tiles/","text":"Saving tile images Tile images can be saved easily with SlideReader . Its easy to define different tile sizes and most importantly the maximum amount of background . from histoprep import SlideReader # Read slide image. reader = SlideReader(slide_path) # Get tile coordinates coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=0.5) display(reader.annotated_thumbnail_tiles) Here we can see that SlideReader automatically calculates the amount of background in each tile, and discarded those with more that 50% background. If we set the maximum amount of background to 100% we get a lot of unnecessary tiles. bad_coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=1.0) display(reader.annotated_thumbnail_tiles) Tiles can also be saved easily and fast! tile_metadata = reader.save_tiles( output_dir=\"/data/tmp\", coordinates=reader.get_tile_coordinates(width=256, max_background=0.5), ) |##########| 605/605 [00:00<00:00, per_image=19.5ms] Now all tiles, the tissue mask, thumbnail and the annotated thumbnail images are saved into the output_dir . /data/tmp \u2514\u2500\u2500 biopsy_slide \u251c\u2500\u2500 annotated_thumbnail_tiles.jpeg \u251c\u2500\u2500 thumbnail.jpeg \u251c\u2500\u2500 tile_metadata.csv \u251c\u2500\u2500 tiles \u2502 \u251c\u2500\u2500 x0_y3584_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2048_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2304_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2560_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2816_w256_h256.jpeg \u2502 \u2514\u2500\u2500 [omitted 601 additional entries] \u2514\u2500\u2500 tissue_mask.jpeg When SlideReader saves individual tiles, it also calculates preprocessing metrics for each imagem which can be used for preprocessing. These are saved to tile_metadata.csv and also returned by the save_tiles function. tile_metadata.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } slide_name x y w h level path background gray_mean red_mean ... saturation_q=0.05 saturation_q=0.1 saturation_q=0.5 saturation_q=0.9 saturation_q=0.95 brightness_q=0.05 brightness_q=0.1 brightness_q=0.5 brightness_q=0.9 brightness_q=0.95 0 biopsy_slide 0 3584 256 256 0 /data/tmp/biopsy_slide/tiles/x0_y3584_w256_h25... 0.557053 223.672 219.163 ... 18 27 44 75 88 162 196 220 228 229 1 biopsy_slide 256 2816 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y2816_w256_h... 0.481506 207.230 221.283 ... 25 30 61 88 99 144 172 220 233 236 2 biopsy_slide 256 3072 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3072_w256_h... 0.099411 178.217 200.113 ... 21 29 60 94 106 127 153 212 228 230 3 biopsy_slide 256 3328 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3328_w256_h... 0.038925 163.737 194.649 ... 25 38 69 102 115 117 138 206 225 228 4 biopsy_slide 256 3584 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3584_w256_h... 0.054428 159.479 195.712 ... 32 41 72 145 150 108 127 209 232 235 5 rows \u00d7 55 columns When there are thousands of slide images to process, writing scripts for saving tiles from each of them can be annoying. For this reason, we wrote the scripts for you! HistoPrep can also be used as an executable. !HistoPrep --help usage: HistoPrep input_dir output_dir width {optional arguments} \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u2550\u2588\u2588\u2554\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d by Jopo666 (2022) positional arguments: input_dir Directory with slides. output_dir For processed slides. width Width of the tile. optional arguments: -h, --help show this help message and exit --overlap Overlap between neighbouring tiles. (default: 0.1) --max_background Maximum allowed background per tile. (default: 0.75) --height Height of the tile. If None, set to width. (default: None) --level Slide level for reading tile regions. (default: 0) --ext [ ...] File extensions to load. If not set, uses all readable extensions. (default: None) --num_workers Number of image saving worker processes. (default: 20) --threshold Threshold for tissue detection. If None, set with Otsu's method. (default: None) --threshold_multiplier Multiply Otsu's threshold with this value. Ignored if threshold is set. (default: 1.05) --max_dimension Maximum dimension for the thumbnail. (default: 16384) --overwrite Removes everything in output folder before saving images. (default: False) --image_format Image format. (default: jpeg) --quality Quality for jpeg compression. (default: 95) --depth Depth for recursively finding slide images from the input_dir. (default: 1) --verbose More verbose output. (default: False)","title":"Saving tiles"},{"location":"examples/cut_tiles/cut_tiles/#saving-tile-images","text":"Tile images can be saved easily with SlideReader . Its easy to define different tile sizes and most importantly the maximum amount of background . from histoprep import SlideReader # Read slide image. reader = SlideReader(slide_path) # Get tile coordinates coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=0.5) display(reader.annotated_thumbnail_tiles) Here we can see that SlideReader automatically calculates the amount of background in each tile, and discarded those with more that 50% background. If we set the maximum amount of background to 100% we get a lot of unnecessary tiles. bad_coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=1.0) display(reader.annotated_thumbnail_tiles) Tiles can also be saved easily and fast! tile_metadata = reader.save_tiles( output_dir=\"/data/tmp\", coordinates=reader.get_tile_coordinates(width=256, max_background=0.5), ) |##########| 605/605 [00:00<00:00, per_image=19.5ms] Now all tiles, the tissue mask, thumbnail and the annotated thumbnail images are saved into the output_dir . /data/tmp \u2514\u2500\u2500 biopsy_slide \u251c\u2500\u2500 annotated_thumbnail_tiles.jpeg \u251c\u2500\u2500 thumbnail.jpeg \u251c\u2500\u2500 tile_metadata.csv \u251c\u2500\u2500 tiles \u2502 \u251c\u2500\u2500 x0_y3584_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2048_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2304_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2560_w256_h256.jpeg \u2502 \u251c\u2500\u2500 x10240_y2816_w256_h256.jpeg \u2502 \u2514\u2500\u2500 [omitted 601 additional entries] \u2514\u2500\u2500 tissue_mask.jpeg When SlideReader saves individual tiles, it also calculates preprocessing metrics for each imagem which can be used for preprocessing. These are saved to tile_metadata.csv and also returned by the save_tiles function. tile_metadata.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } slide_name x y w h level path background gray_mean red_mean ... saturation_q=0.05 saturation_q=0.1 saturation_q=0.5 saturation_q=0.9 saturation_q=0.95 brightness_q=0.05 brightness_q=0.1 brightness_q=0.5 brightness_q=0.9 brightness_q=0.95 0 biopsy_slide 0 3584 256 256 0 /data/tmp/biopsy_slide/tiles/x0_y3584_w256_h25... 0.557053 223.672 219.163 ... 18 27 44 75 88 162 196 220 228 229 1 biopsy_slide 256 2816 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y2816_w256_h... 0.481506 207.230 221.283 ... 25 30 61 88 99 144 172 220 233 236 2 biopsy_slide 256 3072 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3072_w256_h... 0.099411 178.217 200.113 ... 21 29 60 94 106 127 153 212 228 230 3 biopsy_slide 256 3328 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3328_w256_h... 0.038925 163.737 194.649 ... 25 38 69 102 115 117 138 206 225 228 4 biopsy_slide 256 3584 256 256 0 /data/tmp/biopsy_slide/tiles/x256_y3584_w256_h... 0.054428 159.479 195.712 ... 32 41 72 145 150 108 127 209 232 235 5 rows \u00d7 55 columns When there are thousands of slide images to process, writing scripts for saving tiles from each of them can be annoying. For this reason, we wrote the scripts for you! HistoPrep can also be used as an executable. !HistoPrep --help usage: HistoPrep input_dir output_dir width {optional arguments} \u2588\u2588\u2557 \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u2550\u2588\u2588\u2554\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u255d \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d by Jopo666 (2022) positional arguments: input_dir Directory with slides. output_dir For processed slides. width Width of the tile. optional arguments: -h, --help show this help message and exit --overlap Overlap between neighbouring tiles. (default: 0.1) --max_background Maximum allowed background per tile. (default: 0.75) --height Height of the tile. If None, set to width. (default: None) --level Slide level for reading tile regions. (default: 0) --ext [ ...] File extensions to load. If not set, uses all readable extensions. (default: None) --num_workers Number of image saving worker processes. (default: 20) --threshold Threshold for tissue detection. If None, set with Otsu's method. (default: None) --threshold_multiplier Multiply Otsu's threshold with this value. Ignored if threshold is set. (default: 1.05) --max_dimension Maximum dimension for the thumbnail. (default: 16384) --overwrite Removes everything in output folder before saving images. (default: False) --image_format Image format. (default: jpeg) --quality Quality for jpeg compression. (default: 95) --depth Depth for recursively finding slide images from the input_dir. (default: 1) --verbose More verbose output. (default: False)","title":"Saving tile images"},{"location":"examples/dearray/dearray/","text":"Dearraying tissue microarray (TMA) slides. Tissue microarray (TMA) slides are often used in medical image analysis. These slides contain tissue samples from multiple patients, and thus each tissue microarray spot must be separated before cutting the spots into tiles. Luckily this is (also) easy with SlideReader ! from histoprep import SlideReader # Read the slide image. reader = SlideReader(tma_slide_path) display(reader.thumbnail) To separate each spot from the image, SlideReader offers a dearray function. # Dearray spots. reader.dearray(min_area=0.5) # After dearraying, an annotated thumbnail for spots is available. display(reader.annotated_thumbnail_spots) Now each spot can be saved. spot_metadata = reader.save_spots(\"/data/tmp/\") |##########| 31/31 [00:17<00:00, per_image=6.2s] Now all spots, the spot mask, thumbnail and the annotated thumbnail images are saved into the output_dir . /data/tmp/ \u2514\u2500\u2500 tma_slide \u251c\u2500\u2500 annotated_thumbnail_spots.jpeg \u251c\u2500\u2500 spot_mask.jpeg \u251c\u2500\u2500 spot_metadata.csv \u251c\u2500\u2500 spots \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_1.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_10.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_11.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_12.jpeg \u2502 \u2514\u2500\u2500 [omitted 29 additional entries] \u2514\u2500\u2500 thumbnail.jpeg When SlideReader saves individual spots, it does not calculate preprocessing metrics. Information on each spot such as it's coordinates are saved to spot_metadata.csv and also returned by the save_spots function. spot_metadata.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } slide_name x y w h spot_number spot_name path 8 tma_slide 16139 207775 10888 10882 28 tma_slide_spot_28 /data/tmp/tma_slide/spots/tma_slide_spot_28.jpeg 17 tma_slide 16396 193053 10503 11010 19 tma_slide_spot_19 /data/tmp/tma_slide/spots/tma_slide_spot_19.jpeg 25 tma_slide 16652 180507 10632 10626 10 tma_slide_spot_10 /data/tmp/tma_slide/spots/tma_slide_spot_10.jpeg 30 tma_slide 17420 167577 10503 10626 1 tma_slide_spot_1 /data/tmp/tma_slide/spots/tma_slide_spot_1.jpeg 16 tma_slide 39708 194461 10888 11138 20 tma_slide_spot_20 /data/tmp/tma_slide/spots/tma_slide_spot_20.jpeg","title":"Dearraying TMA slides"},{"location":"examples/dearray/dearray/#dearraying-tissue-microarray-tma-slides","text":"Tissue microarray (TMA) slides are often used in medical image analysis. These slides contain tissue samples from multiple patients, and thus each tissue microarray spot must be separated before cutting the spots into tiles. Luckily this is (also) easy with SlideReader ! from histoprep import SlideReader # Read the slide image. reader = SlideReader(tma_slide_path) display(reader.thumbnail) To separate each spot from the image, SlideReader offers a dearray function. # Dearray spots. reader.dearray(min_area=0.5) # After dearraying, an annotated thumbnail for spots is available. display(reader.annotated_thumbnail_spots) Now each spot can be saved. spot_metadata = reader.save_spots(\"/data/tmp/\") |##########| 31/31 [00:17<00:00, per_image=6.2s] Now all spots, the spot mask, thumbnail and the annotated thumbnail images are saved into the output_dir . /data/tmp/ \u2514\u2500\u2500 tma_slide \u251c\u2500\u2500 annotated_thumbnail_spots.jpeg \u251c\u2500\u2500 spot_mask.jpeg \u251c\u2500\u2500 spot_metadata.csv \u251c\u2500\u2500 spots \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_1.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_10.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_11.jpeg \u2502 \u251c\u2500\u2500 TMA09-3_T1_HE_spot_12.jpeg \u2502 \u2514\u2500\u2500 [omitted 29 additional entries] \u2514\u2500\u2500 thumbnail.jpeg When SlideReader saves individual spots, it does not calculate preprocessing metrics. Information on each spot such as it's coordinates are saved to spot_metadata.csv and also returned by the save_spots function. spot_metadata.head(5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } slide_name x y w h spot_number spot_name path 8 tma_slide 16139 207775 10888 10882 28 tma_slide_spot_28 /data/tmp/tma_slide/spots/tma_slide_spot_28.jpeg 17 tma_slide 16396 193053 10503 11010 19 tma_slide_spot_19 /data/tmp/tma_slide/spots/tma_slide_spot_19.jpeg 25 tma_slide 16652 180507 10632 10626 10 tma_slide_spot_10 /data/tmp/tma_slide/spots/tma_slide_spot_10.jpeg 30 tma_slide 17420 167577 10503 10626 1 tma_slide_spot_1 /data/tmp/tma_slide/spots/tma_slide_spot_1.jpeg 16 tma_slide 39708 194461 10888 11138 20 tma_slide_spot_20 /data/tmp/tma_slide/spots/tma_slide_spot_20.jpeg","title":"Dearraying tissue microarray (TMA) slides."},{"location":"examples/panda/panda/","text":"Prostate cANcer graDe Assessment (PANDA) In this use case, we're going to preprocess the PANDA dataset! This is a huge freely available dataset containing prostate cancer biopsies from two different medical centres. You can read more about the dataset in the publication or the kaggle competition . Easiest way to download the dataset is through the Kaggle API. Install kaggle API with # Install/upgrade the Kaggle API. pip install kaggle --upgrade # Then download the dataset. mkdir -p ./PANDA/raw kaggle competitions download -c prostate-cancer-grade-assessment -p ./PANDA/raw Finally when the dataset has downloaded (and been unarchived), the directory structure is like this. ./PANDA/ \u2514\u2500\u2500raw/ \u251c\u2500\u2500 sample_submission.csv \u251c\u2500\u2500 test.csv \u251c\u2500\u2500 train.csv \u251c\u2500\u2500 train_images \u2502 \u251c\u2500\u2500 0005f7aaab2800f6170c399693a96917.tiff \u2502 \u251c\u2500\u2500 000920ad0b612851f8e01bcc880d9b3d.tiff \u2502 \u251c\u2500\u2500 0018ae58b01bdadc8e347995b69f99aa.tiff \u2502 \u251c\u2500\u2500 001c62abd11fa4b57bf7a6c603a11bb9.tiff \u2502 \u251c\u2500\u2500 001d865e65ef5d2579c190a0e0350d8f.tiff \u2502 \u2514\u2500\u2500 ... [omitted 10 611 additional entries] \u2514\u2500\u2500 train_label_masks \u251c\u2500\u2500 0005f7aaab2800f6170c399693a96917_mask.tiff \u251c\u2500\u2500 000920ad0b612851f8e01bcc880d9b3d_mask.tiff \u251c\u2500\u2500 0018ae58b01bdadc8e347995b69f99aa_mask.tiff \u251c\u2500\u2500 001c62abd11fa4b57bf7a6c603a11bb9_mask.tiff \u251c\u2500\u2500 001d865e65ef5d2579c190a0e0350d8f_mask.tiff \u2514\u2500\u2500 ... [omitted 10511 entries] Cut slide images into small tiles First thing to do is to cut the large slide images into smaller images, which can actually be fed to your amazing neural network! Luckily, this is easy with SlideReader . # Read the slide. reader = SlideReader(path=\"./PANDA/raw/train_images/00a7fb880dc12c5de82df39b30533da9.tiff\") # Exctract tile coordinates. coordinates = reader.get_tile_coordinates( width=512, overlap=0.2, max_background=0.6, ) # Then let's display a thumbnail image... display(reader.thumbnail) # ... the tissue mask... display(reader.tissue_mask) # .. and then an annotated thumbnail. display(reader.annotated_thumbnail_tiles) From the above images we can see that the slide is read correctly, tissue mask seems correct, and we managed to cover the whole tissue section in tiles, without including tiles with too much background! Pretty good for a few lines of code. Now can loop over the images in train_images folder and cut each image with the SlideReader function. # NOTE: This cell is just an example and not actually excecuted. import os import pandas from histoprep.helpers import progress_bar combined_metadata = [] for f in progress_bar(os.scandir(\"./PANDA/raw/train_images/\"), desc=\"PANDA\"): # Read slide. reader = SlideReader(f.path) # Cut tiles. slide_metadata = reader.save_tiles( output_dir=\"PANDA/tiles\", coordinates=reader.get_tile_coordinates(width=384, overlap=0.2, max_background=0.6), ) combined_metadata.append(metadata) # Combine metadata. combined_metadata = pandas.stack(combined_metadata) The above cell is a perfectly valid example, but it would be easier to cut all tiles with the HistoPrep excecutable installed alongside the histoprep python module. !HistoPrep ./PANDA/raw/train_images ./PANDA/tiles 384 --overlap 0.2 --max_background 0.6 --ext tiff Now that we have cut all slide images into tiles, we should remove any tiles which come from unwanted regions... Finding outliers Slide images often contain areas, which we are not interested in. These areas might contain fingerprints, bubbles, ink, pen markings or some other shit. Detecting and identifying tiles from these areas is a crucial task, as neural networks might easily overfit these outliers and then give wrong predictions. Let's start by combining the metadata from all of the processed slides. import pandas from histoprep.helpers import combine_metadata # Combine all tile_metadata.csv files from PANDA slides. combined = combine_metadata(\"./PANDA/tiles/\", \"tile_metadata.csv\") print(\"PANDA dataset has {:.1f} million tiles.\".format(len(combined) / 1e6)) # Let's also add a column which tells us where the data came from... train_info = pandas.read_csv(\"./PANDA/raw/train.csv\") provider = dict(zip(train_info.image_id, train_info.data_provider)) combined[\"data_provider\"] = [provider[x] for x in combined.slide_name] # ... and an outlier column where we mark outliers! combined[\"outlier\"] = False Combining metadata: 10615it [00:55] PANDA dataset has 2.8 million tiles. Thats a lot of tiles! Luckily we don't have go through them manually... Let's start by taking a look at the UMAP representation of the preprocessing metrics. UMAP representation requires that install umap-learn with pip install umap-learn . from histoprep import OutlierDetector # Initialize outlier detector. detector = OutlierDetector(combined, num_clusters=10) # Get an UMAP representation with 200k random tiles. coords, indices = detector.umap_representation(verbose=False, max_samples=200_000) # Plot! detector.plot_representation(coords, indices) In the representation, each tile is annotated by it's log(distance) from the origo (the \"mean\" tile), and thus tiles further from the origo are more likely outliers. We can see that the tiles cluster into three bigger groups, which is due to the fact that the PANDA dataset originates from two different medical centres, and is scanned with three scanners. Histological images vary widely due to differences in scanning equipment and sample preparation. Thus, preprocessing is easier if it's done in a per-dataset basis. From here on we'll only process the tiles originating from Radboud University medical centre (only one scanner). radboud = combined[combined.data_provider == \"radboud\"] print(\"There are {:.1f} million tiles from Radboud!\".format(len(radboud) / 1e6)) # Let's visualise the representation again. detector = OutlierDetector(radboud, num_clusters=10) coords, indices = detector.umap_representation(verbose=False, max_samples=200_000) detector.plot_representation(coords, indices) There are 1.3 million tiles from Radboud! Now the representation looks a lot nicer! We can see that there are clear outlier groups, which should be easy to discard. Before we go into automatic outlier detection, we should mark some easy outliers with the OutlierVisualiser . from histoprep import OutlierVisualizer # We'll get a warning here as the dataset contains over a million tiles. visualizer = OutlierVisualizer(radboud) /data/jopo/HistoPrep/histoprep/_outliers/_visualize.py:41: UserWarning: Plotting functions may take a while due to size of the data. warnings.warn( # Plot the 'background' column with example tiles. visualizer.plot_histogram_with_examples(\"background\", log_scale=False) Here we can see that quite many of the tiles contain large amounts of background. This is not good if you're using the RandomResizedCrop function during neural network training to make the network scale invariant. Let's mark tiles with over 60% background as outliers and plot some other preprocessing columns. radboud.loc[radboud.background > 0.6, \"outlier\"] = True visualizer = OutlierVisualizer(radboud[~radboud.outlier]) # Let's plot mean values from the brightness image channels. visualizer.plot_histogram_with_examples(\"brightness_mean\") Here we can easily detect some outliers! There are a lot of completely dark tiles, and only some tiles with weird blue shit (probably pen markings). Let's mark the completely black tiles as outliers and try to extract the blue tiles. radboud.loc[radboud.brightness_mean < 50, \"outlier\"] = True visualizer.plot_histogram_with_examples(\"saturation_mean\") The mean value of the saturation channel seemed to pick up the weird blue tiles. Let's mark these as outliers and move onto automatic outlier detection! radboud.loc[radboud.saturation_mean > 175, \"outlier\"] = True from histoprep import OutlierDetector # Include only non outliers. detector = OutlierDetector(radboud[~radboud.outlier]) print(detector) OutlierDetector(num_clusters=20): 0: dist=36.72 images=1703 1: dist=25.77 images=3000 2: dist=16.73 images=5635 3: dist=16.59 images=4845 4: dist=10.19 images=10231 5: dist=8.54 images=9379 6: dist=7.53 images=18558 7: dist=6.89 images=14857 8: dist=6.81 images=23800 9: dist=6.80 images=41217 10: dist=4.21 images=66061 ... Here we can see that there are several clusters pretty far away from the origo. Let's visualise some random tiles from these clusters! detector.plot_clusters(min_distance=8) Here we can clearly see that OutlierDetector organises the clusters from most likely to least likely outlier. Clusters 0 to 3 are clear outliers, cluster 4 contains tissue regions with dark areas and cluster 5 contains (mostly) good quality tiles. Let's mark clusters 0 to 3 as outliers. radboud[~radboud.outlier].loc[detector.clusters <= 3, \"outlier\"] = True Now we can repeat the automatic outlier detection with the remaning non-outlier tiles! Each iteration we might catch some outliers that were hiding inside larger groups. It's also possible to re-cluster a cluster which contains both good and bad tiles. This way you might separate the good tiles from the bad. python cluster2 = OutlierDetector(radboud[~radboud.outlier][detector.clusters == 2], num_clusters=2) detector = OutlierDetector(radboud[~radboud.outlier]) detector OutlierDetector(num_clusters=20): 0: dist=32.15 images=3526 1: dist=17.48 images=5867 2: dist=15.59 images=6904 3: dist=9.39 images=4305 4: dist=9.24 images=16177 5: dist=8.65 images=8493 6: dist=6.67 images=18028 7: dist=6.67 images=25224 8: dist=6.58 images=19228 9: dist=5.92 images=67838 10: dist=4.34 images=40384 ... detector.plot_clusters(min_distance=10) Here we can see that there were still outliers not picked up during the first iteration. Let's marks clusters 0 and 1 as outliers. You could repeat this a few more times. What to do with the outliers? Now that you've uncovered outliers in the PANDA dataset, we have several options for dealing with them. Remove outliers from the dataset. Label outliers as negative samples. The first option might be the easiest, but could lead to a neural network which might not do so well on a real-world dataset! As the outliers came from real-world dataset, we should include them into the training (and validation) dataset. Each tile can be labeled, for example, as cancer vs. benign based on the Gleason score masks inside train_label_masks folder. After labeling, every tile identified as an outlier during pre-processing could be marked as benign . This would help the network learn to label these outliers as benign and not panic when encoutering these images during evaluation!","title":"Use case: PANDA dataset"},{"location":"examples/panda/panda/#prostate-cancer-grade-assessment-panda","text":"In this use case, we're going to preprocess the PANDA dataset! This is a huge freely available dataset containing prostate cancer biopsies from two different medical centres. You can read more about the dataset in the publication or the kaggle competition . Easiest way to download the dataset is through the Kaggle API. Install kaggle API with # Install/upgrade the Kaggle API. pip install kaggle --upgrade # Then download the dataset. mkdir -p ./PANDA/raw kaggle competitions download -c prostate-cancer-grade-assessment -p ./PANDA/raw Finally when the dataset has downloaded (and been unarchived), the directory structure is like this. ./PANDA/ \u2514\u2500\u2500raw/ \u251c\u2500\u2500 sample_submission.csv \u251c\u2500\u2500 test.csv \u251c\u2500\u2500 train.csv \u251c\u2500\u2500 train_images \u2502 \u251c\u2500\u2500 0005f7aaab2800f6170c399693a96917.tiff \u2502 \u251c\u2500\u2500 000920ad0b612851f8e01bcc880d9b3d.tiff \u2502 \u251c\u2500\u2500 0018ae58b01bdadc8e347995b69f99aa.tiff \u2502 \u251c\u2500\u2500 001c62abd11fa4b57bf7a6c603a11bb9.tiff \u2502 \u251c\u2500\u2500 001d865e65ef5d2579c190a0e0350d8f.tiff \u2502 \u2514\u2500\u2500 ... [omitted 10 611 additional entries] \u2514\u2500\u2500 train_label_masks \u251c\u2500\u2500 0005f7aaab2800f6170c399693a96917_mask.tiff \u251c\u2500\u2500 000920ad0b612851f8e01bcc880d9b3d_mask.tiff \u251c\u2500\u2500 0018ae58b01bdadc8e347995b69f99aa_mask.tiff \u251c\u2500\u2500 001c62abd11fa4b57bf7a6c603a11bb9_mask.tiff \u251c\u2500\u2500 001d865e65ef5d2579c190a0e0350d8f_mask.tiff \u2514\u2500\u2500 ... [omitted 10511 entries]","title":"Prostate cANcer graDe Assessment (PANDA)"},{"location":"examples/panda/panda/#cut-slide-images-into-small-tiles","text":"First thing to do is to cut the large slide images into smaller images, which can actually be fed to your amazing neural network! Luckily, this is easy with SlideReader . # Read the slide. reader = SlideReader(path=\"./PANDA/raw/train_images/00a7fb880dc12c5de82df39b30533da9.tiff\") # Exctract tile coordinates. coordinates = reader.get_tile_coordinates( width=512, overlap=0.2, max_background=0.6, ) # Then let's display a thumbnail image... display(reader.thumbnail) # ... the tissue mask... display(reader.tissue_mask) # .. and then an annotated thumbnail. display(reader.annotated_thumbnail_tiles) From the above images we can see that the slide is read correctly, tissue mask seems correct, and we managed to cover the whole tissue section in tiles, without including tiles with too much background! Pretty good for a few lines of code. Now can loop over the images in train_images folder and cut each image with the SlideReader function. # NOTE: This cell is just an example and not actually excecuted. import os import pandas from histoprep.helpers import progress_bar combined_metadata = [] for f in progress_bar(os.scandir(\"./PANDA/raw/train_images/\"), desc=\"PANDA\"): # Read slide. reader = SlideReader(f.path) # Cut tiles. slide_metadata = reader.save_tiles( output_dir=\"PANDA/tiles\", coordinates=reader.get_tile_coordinates(width=384, overlap=0.2, max_background=0.6), ) combined_metadata.append(metadata) # Combine metadata. combined_metadata = pandas.stack(combined_metadata) The above cell is a perfectly valid example, but it would be easier to cut all tiles with the HistoPrep excecutable installed alongside the histoprep python module. !HistoPrep ./PANDA/raw/train_images ./PANDA/tiles 384 --overlap 0.2 --max_background 0.6 --ext tiff Now that we have cut all slide images into tiles, we should remove any tiles which come from unwanted regions...","title":"Cut slide images into small tiles"},{"location":"examples/panda/panda/#finding-outliers","text":"Slide images often contain areas, which we are not interested in. These areas might contain fingerprints, bubbles, ink, pen markings or some other shit. Detecting and identifying tiles from these areas is a crucial task, as neural networks might easily overfit these outliers and then give wrong predictions. Let's start by combining the metadata from all of the processed slides. import pandas from histoprep.helpers import combine_metadata # Combine all tile_metadata.csv files from PANDA slides. combined = combine_metadata(\"./PANDA/tiles/\", \"tile_metadata.csv\") print(\"PANDA dataset has {:.1f} million tiles.\".format(len(combined) / 1e6)) # Let's also add a column which tells us where the data came from... train_info = pandas.read_csv(\"./PANDA/raw/train.csv\") provider = dict(zip(train_info.image_id, train_info.data_provider)) combined[\"data_provider\"] = [provider[x] for x in combined.slide_name] # ... and an outlier column where we mark outliers! combined[\"outlier\"] = False Combining metadata: 10615it [00:55] PANDA dataset has 2.8 million tiles. Thats a lot of tiles! Luckily we don't have go through them manually... Let's start by taking a look at the UMAP representation of the preprocessing metrics. UMAP representation requires that install umap-learn with pip install umap-learn . from histoprep import OutlierDetector # Initialize outlier detector. detector = OutlierDetector(combined, num_clusters=10) # Get an UMAP representation with 200k random tiles. coords, indices = detector.umap_representation(verbose=False, max_samples=200_000) # Plot! detector.plot_representation(coords, indices) In the representation, each tile is annotated by it's log(distance) from the origo (the \"mean\" tile), and thus tiles further from the origo are more likely outliers. We can see that the tiles cluster into three bigger groups, which is due to the fact that the PANDA dataset originates from two different medical centres, and is scanned with three scanners. Histological images vary widely due to differences in scanning equipment and sample preparation. Thus, preprocessing is easier if it's done in a per-dataset basis. From here on we'll only process the tiles originating from Radboud University medical centre (only one scanner). radboud = combined[combined.data_provider == \"radboud\"] print(\"There are {:.1f} million tiles from Radboud!\".format(len(radboud) / 1e6)) # Let's visualise the representation again. detector = OutlierDetector(radboud, num_clusters=10) coords, indices = detector.umap_representation(verbose=False, max_samples=200_000) detector.plot_representation(coords, indices) There are 1.3 million tiles from Radboud! Now the representation looks a lot nicer! We can see that there are clear outlier groups, which should be easy to discard. Before we go into automatic outlier detection, we should mark some easy outliers with the OutlierVisualiser . from histoprep import OutlierVisualizer # We'll get a warning here as the dataset contains over a million tiles. visualizer = OutlierVisualizer(radboud) /data/jopo/HistoPrep/histoprep/_outliers/_visualize.py:41: UserWarning: Plotting functions may take a while due to size of the data. warnings.warn( # Plot the 'background' column with example tiles. visualizer.plot_histogram_with_examples(\"background\", log_scale=False) Here we can see that quite many of the tiles contain large amounts of background. This is not good if you're using the RandomResizedCrop function during neural network training to make the network scale invariant. Let's mark tiles with over 60% background as outliers and plot some other preprocessing columns. radboud.loc[radboud.background > 0.6, \"outlier\"] = True visualizer = OutlierVisualizer(radboud[~radboud.outlier]) # Let's plot mean values from the brightness image channels. visualizer.plot_histogram_with_examples(\"brightness_mean\") Here we can easily detect some outliers! There are a lot of completely dark tiles, and only some tiles with weird blue shit (probably pen markings). Let's mark the completely black tiles as outliers and try to extract the blue tiles. radboud.loc[radboud.brightness_mean < 50, \"outlier\"] = True visualizer.plot_histogram_with_examples(\"saturation_mean\") The mean value of the saturation channel seemed to pick up the weird blue tiles. Let's mark these as outliers and move onto automatic outlier detection! radboud.loc[radboud.saturation_mean > 175, \"outlier\"] = True from histoprep import OutlierDetector # Include only non outliers. detector = OutlierDetector(radboud[~radboud.outlier]) print(detector) OutlierDetector(num_clusters=20): 0: dist=36.72 images=1703 1: dist=25.77 images=3000 2: dist=16.73 images=5635 3: dist=16.59 images=4845 4: dist=10.19 images=10231 5: dist=8.54 images=9379 6: dist=7.53 images=18558 7: dist=6.89 images=14857 8: dist=6.81 images=23800 9: dist=6.80 images=41217 10: dist=4.21 images=66061 ... Here we can see that there are several clusters pretty far away from the origo. Let's visualise some random tiles from these clusters! detector.plot_clusters(min_distance=8) Here we can clearly see that OutlierDetector organises the clusters from most likely to least likely outlier. Clusters 0 to 3 are clear outliers, cluster 4 contains tissue regions with dark areas and cluster 5 contains (mostly) good quality tiles. Let's mark clusters 0 to 3 as outliers. radboud[~radboud.outlier].loc[detector.clusters <= 3, \"outlier\"] = True Now we can repeat the automatic outlier detection with the remaning non-outlier tiles! Each iteration we might catch some outliers that were hiding inside larger groups. It's also possible to re-cluster a cluster which contains both good and bad tiles. This way you might separate the good tiles from the bad. python cluster2 = OutlierDetector(radboud[~radboud.outlier][detector.clusters == 2], num_clusters=2) detector = OutlierDetector(radboud[~radboud.outlier]) detector OutlierDetector(num_clusters=20): 0: dist=32.15 images=3526 1: dist=17.48 images=5867 2: dist=15.59 images=6904 3: dist=9.39 images=4305 4: dist=9.24 images=16177 5: dist=8.65 images=8493 6: dist=6.67 images=18028 7: dist=6.67 images=25224 8: dist=6.58 images=19228 9: dist=5.92 images=67838 10: dist=4.34 images=40384 ... detector.plot_clusters(min_distance=10) Here we can see that there were still outliers not picked up during the first iteration. Let's marks clusters 0 and 1 as outliers. You could repeat this a few more times.","title":"Finding outliers"},{"location":"examples/panda/panda/#what-to-do-with-the-outliers","text":"Now that you've uncovered outliers in the PANDA dataset, we have several options for dealing with them. Remove outliers from the dataset. Label outliers as negative samples. The first option might be the easiest, but could lead to a neural network which might not do so well on a real-world dataset! As the outliers came from real-world dataset, we should include them into the training (and validation) dataset. Each tile can be labeled, for example, as cancer vs. benign based on the Gleason score masks inside train_label_masks folder. After labeling, every tile identified as an outlier during pre-processing could be marked as benign . This would help the network learn to label these outliers as benign and not panic when encoutering these images during evaluation!","title":"What to do with the outliers?"},{"location":"examples/preprocess/preprocess/","text":"Preprocessing the saved tile images The example images above were relatively clean, but often slide images contain also regions we are not interested in, such as hairs, air bubbles, pen markings etc. Tile images from these regions should be discarded before passing them to your fantastic neural network. In this example we'll use the P rostate c AN cer gra D e A ssessment ( PANDA ) dataset ( publication , kaggle ), which has already been cut into tiles. A more thorough example using the PANDA dataset can be found here . Let's start by combining all metadata. from histoprep.helpers import combine_metadata # Let's start by combining all tile_metadata.csv files. combined = combine_metadata(\"./PANDA/tiles/\", \"tile_metadata.csv\") print(\"PANDA dataset has {:.1f} million tiles.\".format(len(combined) / 1e6)) Combining metadata: 10615it [00:27] PANDA dataset has 2.8 million tiles. Now we have a combined dataframe of 2.8 million tiles from 10 615 prostate biopsy slides. There's bound to be at least a few bad tile images there... Luckily finding them with OutlierDetector and OutlierVisualizer is easy! from histoprep import OutlierVisualizer # Let's add an outlier column to the combined metadata. combined[\"outlier\"] = False visualizer = OutlierVisualizer(combined) # Let's start by visualising the background column visualizer.plot_histogram_with_examples(\"background\", num_examples=16) Here we can see that the amount of background set during saving tiles was a bit too high, luckily we can mark these tiles as outliers! Let's do that and visualise next the gray_mean column. combined.loc[combined.background > 0.6, \"outlier\"] = True # Plot the next column. visualizer.plot_histogram_with_examples(\"gray_mean\") We found more outliers! There are many columns in the tile_metadata.csv file, and we could go through all of them, but let's instead try and detect these outliers automatically! from histoprep import OutlierDetector detector = OutlierDetector(combined) print(detector) OutlierDetector(num_clusters=20): 0: dist=31.48 images=5011 1: dist=15.71 images=14250 2: dist=14.36 images=14374 3: dist=10.36 images=46413 4: dist=9.73 images=58578 5: dist=8.90 images=18104 6: dist=8.74 images=37648 7: dist=8.38 images=18215 8: dist=7.39 images=30246 9: dist=6.86 images=138388 10: dist=5.84 images=322986 ... OutlierDetector performs clustering based on the preprocessing metrics, and orders the clusters from most likely outlier to least likely outlier . Let's inspect the tiles inside the first clusters! detector.plot_clusters(min_distance=10) We can see that the first three clusters contain clear outliers and we can mark these easily as outliers! It's also easy to plot a representation of the preprocessing metrics. # This requires that umap-learn has been installed. coords, indices = detector.umap_representation(verbose=False) detector.plot_representation(coords, indices) We can clearly see 3 larger groups, which are due to the fact that the PANDA dataset has been scanned with three different scanners.","title":"Preprocessing saved tile images"},{"location":"examples/preprocess/preprocess/#preprocessing-the-saved-tile-images","text":"The example images above were relatively clean, but often slide images contain also regions we are not interested in, such as hairs, air bubbles, pen markings etc. Tile images from these regions should be discarded before passing them to your fantastic neural network. In this example we'll use the P rostate c AN cer gra D e A ssessment ( PANDA ) dataset ( publication , kaggle ), which has already been cut into tiles. A more thorough example using the PANDA dataset can be found here . Let's start by combining all metadata. from histoprep.helpers import combine_metadata # Let's start by combining all tile_metadata.csv files. combined = combine_metadata(\"./PANDA/tiles/\", \"tile_metadata.csv\") print(\"PANDA dataset has {:.1f} million tiles.\".format(len(combined) / 1e6)) Combining metadata: 10615it [00:27] PANDA dataset has 2.8 million tiles. Now we have a combined dataframe of 2.8 million tiles from 10 615 prostate biopsy slides. There's bound to be at least a few bad tile images there... Luckily finding them with OutlierDetector and OutlierVisualizer is easy! from histoprep import OutlierVisualizer # Let's add an outlier column to the combined metadata. combined[\"outlier\"] = False visualizer = OutlierVisualizer(combined) # Let's start by visualising the background column visualizer.plot_histogram_with_examples(\"background\", num_examples=16) Here we can see that the amount of background set during saving tiles was a bit too high, luckily we can mark these tiles as outliers! Let's do that and visualise next the gray_mean column. combined.loc[combined.background > 0.6, \"outlier\"] = True # Plot the next column. visualizer.plot_histogram_with_examples(\"gray_mean\") We found more outliers! There are many columns in the tile_metadata.csv file, and we could go through all of them, but let's instead try and detect these outliers automatically! from histoprep import OutlierDetector detector = OutlierDetector(combined) print(detector) OutlierDetector(num_clusters=20): 0: dist=31.48 images=5011 1: dist=15.71 images=14250 2: dist=14.36 images=14374 3: dist=10.36 images=46413 4: dist=9.73 images=58578 5: dist=8.90 images=18104 6: dist=8.74 images=37648 7: dist=8.38 images=18215 8: dist=7.39 images=30246 9: dist=6.86 images=138388 10: dist=5.84 images=322986 ... OutlierDetector performs clustering based on the preprocessing metrics, and orders the clusters from most likely outlier to least likely outlier . Let's inspect the tiles inside the first clusters! detector.plot_clusters(min_distance=10) We can see that the first three clusters contain clear outliers and we can mark these easily as outliers! It's also easy to plot a representation of the preprocessing metrics. # This requires that umap-learn has been installed. coords, indices = detector.umap_representation(verbose=False) detector.plot_representation(coords, indices) We can clearly see 3 larger groups, which are due to the fact that the PANDA dataset has been scanned with three different scanners.","title":"Preprocessing the saved tile images"},{"location":"examples/read_slides/read_slides/","text":"Reading slide images with SlideReader Reading large medical images is easy with histoprep.SlideReader . When slide reader loads an image, a thumbnail of the slide and tissue mask are automatically generated for inspection. from histoprep import SlideReader # Read slide image. reader = SlideReader(slide_path) # Access thumbnail and tissue mask as attributes. display(reader.thumbnail) display(reader.tissue_mask) It's possible to adjust the threshold for tissue detection or the size of the thumbnail. # Thumbnail can be adjusted when reading the slide... reader = SlideReader(slide_path, preferred_dimension=2048) print(reader.thumbnail.size) # ... or after the slide has been read! reader.get_thumbnail(preferred_dimension=10_000) print(reader.thumbnail.size) (2016, 272) (8064, 1088) # Same goes for tissue detection. reader = SlideReader(slide_path, threshold_multiplier=1.0) display(reader.tissue_mask) # Change to a too low threshold. reader.detect_tissue(threshold=180) display(reader.tissue_mask) # Default settings work fine 99% of the time. reader.detect_tissue() display(reader.tissue_mask) SlideReader object has a __repr__ which shows some information about the slide. print(reader) biopsy_slide: Dimensions: (4352, 32256) Downsamples: [1, 2, 4] Channel order: XYWH Dimension order: HW Tissue threshold: 221 Backend: OPENSLIDE Often large slide images are divided into different levels with different downsamples. print(reader.level_dimensions) print(reader.level_downsamples) {0: (4352, 32256), 1: (1088, 8064), 2: (272, 2016)} {0: (1.0, 1.0), 1: (4.0, 4.0), 2: (16.0, 16.0)} You can read individual regions of the slide at different downsamples. # Read region from full resolution.... display(reader.read_region(xywh=(2048, 2048, 256, 256))) # ... and from downsample 4 (level=1). display(reader.read_region(xywh=(2048, 2048, 256, 256), level=1)) It's also easy to divide the slide into tiles. coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=0.5) print(\"Cut the slide into {} tiles.\".format(len(coords))) # After cutting, an annotated thumbnail can be visualised. display(reader.annotated_thumbnail_tiles) Cut the slide into 741 tiles.","title":"Reading slides"},{"location":"examples/read_slides/read_slides/#reading-slide-images-with-slidereader","text":"Reading large medical images is easy with histoprep.SlideReader . When slide reader loads an image, a thumbnail of the slide and tissue mask are automatically generated for inspection. from histoprep import SlideReader # Read slide image. reader = SlideReader(slide_path) # Access thumbnail and tissue mask as attributes. display(reader.thumbnail) display(reader.tissue_mask) It's possible to adjust the threshold for tissue detection or the size of the thumbnail. # Thumbnail can be adjusted when reading the slide... reader = SlideReader(slide_path, preferred_dimension=2048) print(reader.thumbnail.size) # ... or after the slide has been read! reader.get_thumbnail(preferred_dimension=10_000) print(reader.thumbnail.size) (2016, 272) (8064, 1088) # Same goes for tissue detection. reader = SlideReader(slide_path, threshold_multiplier=1.0) display(reader.tissue_mask) # Change to a too low threshold. reader.detect_tissue(threshold=180) display(reader.tissue_mask) # Default settings work fine 99% of the time. reader.detect_tissue() display(reader.tissue_mask) SlideReader object has a __repr__ which shows some information about the slide. print(reader) biopsy_slide: Dimensions: (4352, 32256) Downsamples: [1, 2, 4] Channel order: XYWH Dimension order: HW Tissue threshold: 221 Backend: OPENSLIDE Often large slide images are divided into different levels with different downsamples. print(reader.level_dimensions) print(reader.level_downsamples) {0: (4352, 32256), 1: (1088, 8064), 2: (272, 2016)} {0: (1.0, 1.0), 1: (4.0, 4.0), 2: (16.0, 16.0)} You can read individual regions of the slide at different downsamples. # Read region from full resolution.... display(reader.read_region(xywh=(2048, 2048, 256, 256))) # ... and from downsample 4 (level=1). display(reader.read_region(xywh=(2048, 2048, 256, 256), level=1)) It's also easy to divide the slide into tiles. coords = reader.get_tile_coordinates(width=256, overlap=0.1, max_background=0.5) print(\"Cut the slide into {} tiles.\".format(len(coords))) # After cutting, an annotated thumbnail can be visualised. display(reader.annotated_thumbnail_tiles) Cut the slide into 741 tiles.","title":"Reading slide images with SlideReader"}]}